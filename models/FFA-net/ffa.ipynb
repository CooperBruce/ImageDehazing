{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "modelSub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abubakrsiddq/ImageDehazing/blob/main/models/FFA-net/ffa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "scrolled": false,
        "id": "N39U696_KnKD"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NetxtfKRKv7K",
        "outputId": "9bb71057-bbc3-443f-ab36-d5d2824ad634"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FE6nygwKnKd"
      },
      "source": [
        "# Preprocessing and loading of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQvDpNGaB_l"
      },
      "source": [
        "#ls drive/MyDrive/reside/archive/clear_images drive/MyDrive/reside/archive/haze  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "uk0gyj-8KnKe"
      },
      "source": [
        "# function to load the image in the form of tensors.\n",
        "\n",
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (412, 548), antialias = True)\n",
        "    img = img / 255.0\n",
        "    return img"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "vvpitygGKnKf"
      },
      "source": [
        "# function to get the path of individual image.\n",
        "\n",
        "def data_path(orig_img_path, hazy_img_path):\n",
        "    \n",
        "    train_img = []\n",
        "    val_img = []\n",
        "    \n",
        "    orig_img = glob.glob(orig_img_path + '/*.jpg')\n",
        "    n = len(orig_img)\n",
        "    random.shuffle(orig_img)\n",
        "    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\n",
        "    val_keys = orig_img[int(0.9*n):]\n",
        "    \n",
        "    split_dict = {}\n",
        "    for key in train_keys:\n",
        "        split_dict[key] = 'train'\n",
        "    for key in val_keys:\n",
        "        split_dict[key] = 'val'\n",
        "        \n",
        "    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\n",
        "    for img in hazy_img:\n",
        "        img_name = img.split('/')[-1]\n",
        "        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'\n",
        "        if (split_dict[orig_path] == 'train'):\n",
        "            train_img.append([img, orig_path])\n",
        "        else:\n",
        "            val_img.append([img, orig_path])\n",
        "            \n",
        "    return train_img, val_img"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "D-194d5sKnKg"
      },
      "source": [
        "# function to load tensor image data in batches.\n",
        "\n",
        "def dataloader(train_data, val_data, batch_size):\n",
        "    \n",
        "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    return train, val"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "2aU_zzDHKnKh"
      },
      "source": [
        "# function to display output.\n",
        "import cv2\n",
        "def display_img(model, hazy_img, orig_img):\n",
        "    \n",
        "    dehazed_img = model(hazy_img, training = True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    \n",
        "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
        "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()\n",
        "    #print(\"input image quality\",display_list)#niqe(cv2.imread(display_list[1])))\n",
        "    #print(\"input image quality\",niqe(cv2.imread(display_list[2])))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuypKuZZKnKi"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsyBHZ12mMQ1"
      },
      "source": [
        "def default_conv(in_channels, out_channels, kernel_size, bias=True,activation='relu'):\n",
        "    return tf.keras.layers.Conv2D(out_channels, kernel_size,padding='same', use_bias=bias,activation=activation)\n",
        "    \n",
        "class PixAtLayer(tf.keras.Model):\n",
        "    def __init__(self, channel):\n",
        "        super(PixAtLayer, self).__init__()\n",
        "        self.pa = tf.keras.Sequential()\n",
        "        self.pa.add(tf.keras.layers.Conv2D(channel // 8, 1, padding='valid',activation='relu'))\n",
        "        self.pa.add(tf.keras.layers.Conv2D( 1, 1,activation='sigmoid'))\n",
        "    def call(self, x):\n",
        "        y = self.pa(x)\n",
        "        #return y\n",
        "        return x * y\n",
        "\n",
        "    def model(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "def adapavgpooling(x,outsize):\n",
        "    x_shape=tf.keras.backend.int_shape(x)\n",
        "    batchsize1,dim1,dim2,channels1=x_shape\n",
        "    stride=np.floor(dim1/outsize).astype(np.int32)\n",
        "    kernels=dim1-(outsize-1)*stride\n",
        "    adpooling=tf.keras.layers.AveragePooling2D(pool_size=(kernels,kernels),strides=(stride,stride))(x)\n",
        "    \n",
        "    return adpooling\n",
        "\n",
        "class ChanAtLayer(tf.keras.Model):\n",
        "  def __init__(self, channel):\n",
        "      super(ChanAtLayer, self).__init__()\n",
        "      #self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "      self.ca = tf.keras.Sequential()\n",
        "      self.ca.add(tf.keras.layers.Conv2D(channel // 8, 1,activation='relu'))\n",
        "      self.ca.add(tf.keras.layers.Conv2D(channel, 1, activation='sigmoid'))\n",
        "\n",
        "  def call(self, x):\n",
        "      y = adapavgpooling(x,1)\n",
        "      y = self.ca(y)\n",
        "      #return y\n",
        "      return x * y\n",
        "\n",
        "  def model(self):\n",
        "        x = Input(shape = (412, 548, 64))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzcin-mNmRwv"
      },
      "source": [
        "#sub = PixAtLayer(64)\n",
        "#sub.model().summary()\n",
        "#sub1 = ChanAtLayer(64)\n",
        "#sub1.model().summary()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW2s_Zopmb3q"
      },
      "source": [
        "class Block_layer(tf.keras.Model):\n",
        "    def __init__(self, conv, dim, kernel_size,):\n",
        "        super(Block_layer, self).__init__()\n",
        "        self.conv1=conv(dim,dim, kernel_size, bias=True,activation='relu')\n",
        "        \n",
        "        self.conv2=conv(dim,dim, kernel_size, bias=True)\n",
        "        self.calayer=ChanAtLayer(dim)\n",
        "        self.palayer=PixAtLayer(dim)\n",
        "    def call(self, x):\n",
        "        res=self.conv1(x)\n",
        "        res=res+x \n",
        "        res=self.conv2(res)\n",
        "        res=self.calayer(res)\n",
        "        res=self.palayer(res)\n",
        "        res += x \n",
        "        return res\n",
        "\n",
        "    def model(self):\n",
        "        x = Input(shape = (412, 548,64))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzP1jFwLmfr3",
        "outputId": "72ecdaf1-35ed-4d11-d1f3-3673a20ac16a"
      },
      "source": [
        "sub1 =Block_layer(default_conv,64,3)\n",
        "sub1.model().summary()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_22 (InputLayer)           [(None, 412, 548, 64 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1194 (Conv2D)            (None, 412, 548, 64) 36928       input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_7 (TFOpLam (None, 412, 548, 64) 0           conv2d_1194[0][0]                \n",
            "                                                                 input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1195 (Conv2D)            (None, 412, 548, 64) 36928       tf.__operators__.add_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "chan_at_layer_183 (ChanAtLayer) (None, 412, 548, 64) 1096        conv2d_1195[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "pix_at_layer_192 (PixAtLayer)   (None, 412, 548, 64) 529         chan_at_layer_183[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_8 (TFOpLam (None, 412, 548, 64) 0           pix_at_layer_192[0][0]           \n",
            "                                                                 input_22[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 75,481\n",
            "Trainable params: 75,481\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOzDIDpqjZBn"
      },
      "source": [
        "class Group_layer(tf.keras.Model):\n",
        "    def __init__(self, conv, dim, kernel_size, blocks):\n",
        "        super(Group_layer, self).__init__()\n",
        "        modules = [ Block_layer(conv, dim, kernel_size)  for _ in range(blocks)]\n",
        "        modules.append(tf.keras.layers.Conv2D(dim, kernel_size,padding='same'))\n",
        "        self.gp = tf.keras.Sequential()\n",
        "        for lay in modules:\n",
        "          self.gp.add(lay)\n",
        "        \n",
        "    def call(self,input_tensor):\n",
        "        res = self.gp(input_tensor)\n",
        "        #res =tf.keras.layers.Add()([res,input_tensor])\n",
        "        res+=input_tensor\n",
        "        return res\n",
        "\n",
        "    def model(self):\n",
        "        x = Input(shape = (412, 548,64))\n",
        "        return Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IypzZI1tnZ2X",
        "outputId": "56d3bd19-c092-471b-f9a0-34ff79a370fb"
      },
      "source": [
        "sub1 =Group_layer(default_conv,64,3,6)\n",
        "sub1.model().summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           [(None, 412, 548, 64 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_331 (Sequential)     (None, 412, 548, 64) 489814      input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_9 (TFOpLam (None, 412, 548, 64) 0           sequential_331[0][0]             \n",
            "                                                                 input_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 489,814\n",
            "Trainable params: 489,814\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTCX-CqzehI3"
      },
      "source": [
        "class FFAnet(tf.keras.Model):\n",
        "    def __init__(self,gps,blocks,conv=default_conv):\n",
        "        super(FFAnet, self).__init__()\n",
        "        # define all layers in init\n",
        "        # Layer of Block 1\n",
        "        self.gps=gps\n",
        "        self.dim=64\n",
        "        kernel_size=3\n",
        "        pre_process = [tf.keras.layers.Conv2D(self.dim, kernel_size)]\n",
        "        assert self.gps==3\n",
        "        self.g1= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g2= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g3= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        l=[\n",
        "            adapavgpooling(),\n",
        "            tf.keras.layers.Conv2D(self.dim//16,1,padding='valid'),\n",
        "            \n",
        "            tf.keras.layers.Conv2D(self.dim*self.gps, 1, padding='valid', use_bias=True,activation='sigmoid')\n",
        "            \n",
        "            ]\n",
        "       \n",
        "        self.ca=tf.keras.Sequential()\n",
        "        for lay in l:\n",
        "          self.ca.add(lay)\n",
        "        self.palayer=PixAtLayer(self.dim)\n",
        "\n",
        "        post_precess = [\n",
        "            conv(self.dim, self.dim, kernel_size),\n",
        "            conv(self.dim, 3, kernel_size)]\n",
        "\n",
        "        self.pre = tf.keras.Sequential(tf.keras.layers.Conv2D(self.dim, kernel_size,padding='same'))\n",
        "\n",
        "        self.post = tf.keras.Sequential()\n",
        "        for lay in post_precess:\n",
        "          self.post.add(lay)\n",
        "        \n",
        "    def call(self, input_tensor, training=False):\n",
        "        # forward pass: block 1 \n",
        "        x = self.pre(input_tensor)\n",
        "        res1=self.g1(x)\n",
        "        res2=self.g2(res1)\n",
        "        res3=self.g3(res2)\n",
        "        w=tf.keras.layers.concatenate([res1,res2,res3],axis=-1)\n",
        "        #w=self.ca(w)\n",
        "        return w\n",
        "       \n",
        "    def model(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "    def build_graph(self):\n",
        "        x = Input(shape=(412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "htg4Y_MW0Jfo",
        "outputId": "85e9ff0a-d795-41c4-c1de-024cd4d15e4b"
      },
      "source": [
        "sub =FFAnet(gps=3,blocks=6)\n",
        "sub.model().summary()\n",
        "dot_img_file = '/tmp/model_1.png'\n",
        "tf.keras.utils.plot_model(\n",
        "    sub.build_graph(),                      # here is the trick (for now)\n",
        "    to_file='model.png', dpi=96,              # saving  \n",
        "    show_shapes=True, show_layer_names=True,  # show shapes and layer name\n",
        "    expand_nested=False                       # will show nested block\n",
        ")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-dab330b764e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mFFAnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdot_img_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/tmp/model_1.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m tf.keras.utils.plot_model(\n\u001b[1;32m      5\u001b[0m     \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                      \u001b[0;31m# here is the trick (for now)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-0fa1842c42b7>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m412\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m548\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-0fa1842c42b7>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tensor, training)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mres3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    237\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_1468 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 192)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "HhB7n03AKnKo"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 10\n",
        "batch_size = 8\n",
        "k_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      \n",
        "regularizer = tf.keras.regularizers.L2(1e-4)\n",
        "b_init = tf.constant_initializer()\n",
        "\n",
        "train_data, val_data = data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze')\n",
        "train, val = dataloader(train_data, val_data, batch_size)\n",
        "\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "net = ModelSubClassing()\n",
        "\n",
        "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\n",
        "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_kg_hide-output": true,
        "id": "L7pz9bV9KnKr"
      },
      "source": [
        "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
        "        start_time_epoch = time.time()\n",
        "        start_time_step = time.time()\n",
        "        \n",
        "        # training loop\n",
        "        \n",
        "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "                train_logits = net(train_batch_haze, training = True)\n",
        "                #print(train_logits.shape)\n",
        "                loss = mean_squared_error(train_batch_orig, train_logits)\n",
        "\n",
        "            grads = tape.gradient(loss, net.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
        "\n",
        "            train_loss_tracker.update_state(train_batch_orig, train_logits)\n",
        "            if step == 0:\n",
        "                print('[', end='')\n",
        "            if step % 64 == 0:\n",
        "                print('=', end='')\n",
        "        \n",
        "        print(']', end='')\n",
        "        print('  -  ', end='')\n",
        "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
        "        \n",
        "        # validation loop\n",
        "        \n",
        "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
        "            val_logits = net(val_batch_haze, training = False)\n",
        "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
        "            \n",
        "            if step % 32 ==0:\n",
        "                display_img(net, val_batch_haze, val_batch_orig)\n",
        "        \n",
        "        print('  -  ', end='')\n",
        "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
        "        print('  -  ', end=' ')\n",
        "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
        "        \n",
        "        net.save('trained_model')           # save the model(variables, weights, etc)\n",
        "        train_loss_tracker.reset_states()\n",
        "        val_loss_tracker.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "sbnB0QNYKnKs",
        "outputId": "3cc91f0e-4874-48a1-9aef-879b642bd5e5"
      },
      "source": [
        "%%time\n",
        "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0 [="
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b0302f0e0cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-814522eb9084>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_haze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_orig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2574\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2575\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2577\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMg7MNzdkWCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fdc74a1-e20a-440a-9799-36088c824204"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 412, 548, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 412, 548, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 412, 548, 3)       1731      \n",
            "=================================================================\n",
            "Total params: 3,523\n",
            "Trainable params: 3,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CinhPC_5OSPB"
      },
      "source": [
        "## Learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iylDejI5qxZH"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size,padding=(kernel_size//2), bias=bias)\n",
        "    \n",
        "class PALayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(PALayer, self).__init__()\n",
        "        self.pa = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        y = self.pa(x)\n",
        "        return x * y\n",
        "\n",
        "class CALayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(CALayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.ca = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.ca(y)\n",
        "        return x * y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, conv, dim, kernel_size,):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1=conv(dim, dim, kernel_size, bias=True)\n",
        "        self.act1=nn.ReLU(inplace=True)\n",
        "        self.conv2=conv(dim,dim,kernel_size,bias=True)\n",
        "        self.calayer=CALayer(dim)\n",
        "        self.palayer=PALayer(dim)\n",
        "    def forward(self, x):\n",
        "        res=self.act1(self.conv1(x))\n",
        "        res=res+x \n",
        "        res=self.conv2(res)\n",
        "        res=self.calayer(res)\n",
        "        res=self.palayer(res)\n",
        "        res += x \n",
        "        return res\n",
        "class Group(nn.Module):\n",
        "    def __init__(self, conv, dim, kernel_size, blocks):\n",
        "        super(Group, self).__init__()\n",
        "        modules = [ Block(conv, dim, kernel_size)  for _ in range(blocks)]\n",
        "        modules.append(conv(dim, dim, kernel_size))\n",
        "        self.gp = nn.Sequential(*modules)\n",
        "    def forward(self, x):\n",
        "        res = self.gp(x)\n",
        "        res += x\n",
        "        return res\n",
        "\n",
        "class FFA(nn.Module):\n",
        "    def __init__(self,gps,blocks,conv=default_conv):\n",
        "        super(FFA, self).__init__()\n",
        "        self.gps=gps\n",
        "        self.dim=64\n",
        "        kernel_size=3\n",
        "        pre_process = [conv(3, self.dim, kernel_size)]\n",
        "        assert self.gps==3\n",
        "        self.g1= Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g2= Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g3= Group(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.ca=nn.Sequential(*[\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(self.dim*self.gps,self.dim//16,1,padding=0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.dim//16, self.dim*self.gps, 1, padding=0, bias=True),\n",
        "            nn.Sigmoid()\n",
        "            ])\n",
        "        self.palayer=PALayer(self.dim)\n",
        "\n",
        "        post_precess = [\n",
        "            conv(self.dim, self.dim, kernel_size),\n",
        "            conv(self.dim, 3, kernel_size)]\n",
        "\n",
        "        self.pre = nn.Sequential(*pre_process)\n",
        "        self.post = nn.Sequential(*post_precess)\n",
        "\n",
        "    def forward(self, x1):\n",
        "        x = self.pre(x1)\n",
        "        res1=self.g1(x)\n",
        "        res2=self.g2(res1)\n",
        "        res3=self.g3(res2)\n",
        "        #return res3\n",
        "        w=torch.cat([res1,res2,res3],dim=1)\n",
        "        w=self.ca(w)\n",
        "        return w\n",
        "        w=w.view(-1,self.gps,self.dim)[:,:,:,None,None]\n",
        "        out=w[:,0,::]*res1+w[:,1,::]*res2+w[:,2,::]*res3\n",
        "        out=self.palayer(out)\n",
        "        x=self.post(out)\n",
        "        return x + x1"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awsfQhl5q2rw",
        "outputId": "4ccd2110-d76c-4ded-eaf8-b270b1283896",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "net=FFA(gps=3,blocks=6)\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "print(summary(net, (3, 412, 548)))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 412, 548]           1,792\n",
            "            Conv2d-2         [-1, 64, 412, 548]          36,928\n",
            "              ReLU-3         [-1, 64, 412, 548]               0\n",
            "            Conv2d-4         [-1, 64, 412, 548]          36,928\n",
            " AdaptiveAvgPool2d-5             [-1, 64, 1, 1]               0\n",
            "            Conv2d-6              [-1, 8, 1, 1]             520\n",
            "              ReLU-7              [-1, 8, 1, 1]               0\n",
            "            Conv2d-8             [-1, 64, 1, 1]             576\n",
            "           Sigmoid-9             [-1, 64, 1, 1]               0\n",
            "          CALayer-10         [-1, 64, 412, 548]               0\n",
            "           Conv2d-11          [-1, 8, 412, 548]             520\n",
            "             ReLU-12          [-1, 8, 412, 548]               0\n",
            "           Conv2d-13          [-1, 1, 412, 548]               9\n",
            "          Sigmoid-14          [-1, 1, 412, 548]               0\n",
            "          PALayer-15         [-1, 64, 412, 548]               0\n",
            "            Block-16         [-1, 64, 412, 548]               0\n",
            "           Conv2d-17         [-1, 64, 412, 548]          36,928\n",
            "             ReLU-18         [-1, 64, 412, 548]               0\n",
            "           Conv2d-19         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-20             [-1, 64, 1, 1]               0\n",
            "           Conv2d-21              [-1, 8, 1, 1]             520\n",
            "             ReLU-22              [-1, 8, 1, 1]               0\n",
            "           Conv2d-23             [-1, 64, 1, 1]             576\n",
            "          Sigmoid-24             [-1, 64, 1, 1]               0\n",
            "          CALayer-25         [-1, 64, 412, 548]               0\n",
            "           Conv2d-26          [-1, 8, 412, 548]             520\n",
            "             ReLU-27          [-1, 8, 412, 548]               0\n",
            "           Conv2d-28          [-1, 1, 412, 548]               9\n",
            "          Sigmoid-29          [-1, 1, 412, 548]               0\n",
            "          PALayer-30         [-1, 64, 412, 548]               0\n",
            "            Block-31         [-1, 64, 412, 548]               0\n",
            "           Conv2d-32         [-1, 64, 412, 548]          36,928\n",
            "             ReLU-33         [-1, 64, 412, 548]               0\n",
            "           Conv2d-34         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-35             [-1, 64, 1, 1]               0\n",
            "           Conv2d-36              [-1, 8, 1, 1]             520\n",
            "             ReLU-37              [-1, 8, 1, 1]               0\n",
            "           Conv2d-38             [-1, 64, 1, 1]             576\n",
            "          Sigmoid-39             [-1, 64, 1, 1]               0\n",
            "          CALayer-40         [-1, 64, 412, 548]               0\n",
            "           Conv2d-41          [-1, 8, 412, 548]             520\n",
            "             ReLU-42          [-1, 8, 412, 548]               0\n",
            "           Conv2d-43          [-1, 1, 412, 548]               9\n",
            "          Sigmoid-44          [-1, 1, 412, 548]               0\n",
            "          PALayer-45         [-1, 64, 412, 548]               0\n",
            "            Block-46         [-1, 64, 412, 548]               0\n",
            "           Conv2d-47         [-1, 64, 412, 548]          36,928\n",
            "             ReLU-48         [-1, 64, 412, 548]               0\n",
            "           Conv2d-49         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-50             [-1, 64, 1, 1]               0\n",
            "           Conv2d-51              [-1, 8, 1, 1]             520\n",
            "             ReLU-52              [-1, 8, 1, 1]               0\n",
            "           Conv2d-53             [-1, 64, 1, 1]             576\n",
            "          Sigmoid-54             [-1, 64, 1, 1]               0\n",
            "          CALayer-55         [-1, 64, 412, 548]               0\n",
            "           Conv2d-56          [-1, 8, 412, 548]             520\n",
            "             ReLU-57          [-1, 8, 412, 548]               0\n",
            "           Conv2d-58          [-1, 1, 412, 548]               9\n",
            "          Sigmoid-59          [-1, 1, 412, 548]               0\n",
            "          PALayer-60         [-1, 64, 412, 548]               0\n",
            "            Block-61         [-1, 64, 412, 548]               0\n",
            "           Conv2d-62         [-1, 64, 412, 548]          36,928\n",
            "             ReLU-63         [-1, 64, 412, 548]               0\n",
            "           Conv2d-64         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-65             [-1, 64, 1, 1]               0\n",
            "           Conv2d-66              [-1, 8, 1, 1]             520\n",
            "             ReLU-67              [-1, 8, 1, 1]               0\n",
            "           Conv2d-68             [-1, 64, 1, 1]             576\n",
            "          Sigmoid-69             [-1, 64, 1, 1]               0\n",
            "          CALayer-70         [-1, 64, 412, 548]               0\n",
            "           Conv2d-71          [-1, 8, 412, 548]             520\n",
            "             ReLU-72          [-1, 8, 412, 548]               0\n",
            "           Conv2d-73          [-1, 1, 412, 548]               9\n",
            "          Sigmoid-74          [-1, 1, 412, 548]               0\n",
            "          PALayer-75         [-1, 64, 412, 548]               0\n",
            "            Block-76         [-1, 64, 412, 548]               0\n",
            "           Conv2d-77         [-1, 64, 412, 548]          36,928\n",
            "             ReLU-78         [-1, 64, 412, 548]               0\n",
            "           Conv2d-79         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-80             [-1, 64, 1, 1]               0\n",
            "           Conv2d-81              [-1, 8, 1, 1]             520\n",
            "             ReLU-82              [-1, 8, 1, 1]               0\n",
            "           Conv2d-83             [-1, 64, 1, 1]             576\n",
            "          Sigmoid-84             [-1, 64, 1, 1]               0\n",
            "          CALayer-85         [-1, 64, 412, 548]               0\n",
            "           Conv2d-86          [-1, 8, 412, 548]             520\n",
            "             ReLU-87          [-1, 8, 412, 548]               0\n",
            "           Conv2d-88          [-1, 1, 412, 548]               9\n",
            "          Sigmoid-89          [-1, 1, 412, 548]               0\n",
            "          PALayer-90         [-1, 64, 412, 548]               0\n",
            "            Block-91         [-1, 64, 412, 548]               0\n",
            "           Conv2d-92         [-1, 64, 412, 548]          36,928\n",
            "            Group-93         [-1, 64, 412, 548]               0\n",
            "           Conv2d-94         [-1, 64, 412, 548]          36,928\n",
            "             ReLU-95         [-1, 64, 412, 548]               0\n",
            "           Conv2d-96         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-97             [-1, 64, 1, 1]               0\n",
            "           Conv2d-98              [-1, 8, 1, 1]             520\n",
            "             ReLU-99              [-1, 8, 1, 1]               0\n",
            "          Conv2d-100             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-101             [-1, 64, 1, 1]               0\n",
            "         CALayer-102         [-1, 64, 412, 548]               0\n",
            "          Conv2d-103          [-1, 8, 412, 548]             520\n",
            "            ReLU-104          [-1, 8, 412, 548]               0\n",
            "          Conv2d-105          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-106          [-1, 1, 412, 548]               0\n",
            "         PALayer-107         [-1, 64, 412, 548]               0\n",
            "           Block-108         [-1, 64, 412, 548]               0\n",
            "          Conv2d-109         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-110         [-1, 64, 412, 548]               0\n",
            "          Conv2d-111         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-112             [-1, 64, 1, 1]               0\n",
            "          Conv2d-113              [-1, 8, 1, 1]             520\n",
            "            ReLU-114              [-1, 8, 1, 1]               0\n",
            "          Conv2d-115             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-116             [-1, 64, 1, 1]               0\n",
            "         CALayer-117         [-1, 64, 412, 548]               0\n",
            "          Conv2d-118          [-1, 8, 412, 548]             520\n",
            "            ReLU-119          [-1, 8, 412, 548]               0\n",
            "          Conv2d-120          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-121          [-1, 1, 412, 548]               0\n",
            "         PALayer-122         [-1, 64, 412, 548]               0\n",
            "           Block-123         [-1, 64, 412, 548]               0\n",
            "          Conv2d-124         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-125         [-1, 64, 412, 548]               0\n",
            "          Conv2d-126         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-127             [-1, 64, 1, 1]               0\n",
            "          Conv2d-128              [-1, 8, 1, 1]             520\n",
            "            ReLU-129              [-1, 8, 1, 1]               0\n",
            "          Conv2d-130             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-131             [-1, 64, 1, 1]               0\n",
            "         CALayer-132         [-1, 64, 412, 548]               0\n",
            "          Conv2d-133          [-1, 8, 412, 548]             520\n",
            "            ReLU-134          [-1, 8, 412, 548]               0\n",
            "          Conv2d-135          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-136          [-1, 1, 412, 548]               0\n",
            "         PALayer-137         [-1, 64, 412, 548]               0\n",
            "           Block-138         [-1, 64, 412, 548]               0\n",
            "          Conv2d-139         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-140         [-1, 64, 412, 548]               0\n",
            "          Conv2d-141         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-142             [-1, 64, 1, 1]               0\n",
            "          Conv2d-143              [-1, 8, 1, 1]             520\n",
            "            ReLU-144              [-1, 8, 1, 1]               0\n",
            "          Conv2d-145             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-146             [-1, 64, 1, 1]               0\n",
            "         CALayer-147         [-1, 64, 412, 548]               0\n",
            "          Conv2d-148          [-1, 8, 412, 548]             520\n",
            "            ReLU-149          [-1, 8, 412, 548]               0\n",
            "          Conv2d-150          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-151          [-1, 1, 412, 548]               0\n",
            "         PALayer-152         [-1, 64, 412, 548]               0\n",
            "           Block-153         [-1, 64, 412, 548]               0\n",
            "          Conv2d-154         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-155         [-1, 64, 412, 548]               0\n",
            "          Conv2d-156         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-157             [-1, 64, 1, 1]               0\n",
            "          Conv2d-158              [-1, 8, 1, 1]             520\n",
            "            ReLU-159              [-1, 8, 1, 1]               0\n",
            "          Conv2d-160             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-161             [-1, 64, 1, 1]               0\n",
            "         CALayer-162         [-1, 64, 412, 548]               0\n",
            "          Conv2d-163          [-1, 8, 412, 548]             520\n",
            "            ReLU-164          [-1, 8, 412, 548]               0\n",
            "          Conv2d-165          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-166          [-1, 1, 412, 548]               0\n",
            "         PALayer-167         [-1, 64, 412, 548]               0\n",
            "           Block-168         [-1, 64, 412, 548]               0\n",
            "          Conv2d-169         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-170         [-1, 64, 412, 548]               0\n",
            "          Conv2d-171         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-172             [-1, 64, 1, 1]               0\n",
            "          Conv2d-173              [-1, 8, 1, 1]             520\n",
            "            ReLU-174              [-1, 8, 1, 1]               0\n",
            "          Conv2d-175             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-176             [-1, 64, 1, 1]               0\n",
            "         CALayer-177         [-1, 64, 412, 548]               0\n",
            "          Conv2d-178          [-1, 8, 412, 548]             520\n",
            "            ReLU-179          [-1, 8, 412, 548]               0\n",
            "          Conv2d-180          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-181          [-1, 1, 412, 548]               0\n",
            "         PALayer-182         [-1, 64, 412, 548]               0\n",
            "           Block-183         [-1, 64, 412, 548]               0\n",
            "          Conv2d-184         [-1, 64, 412, 548]          36,928\n",
            "           Group-185         [-1, 64, 412, 548]               0\n",
            "          Conv2d-186         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-187         [-1, 64, 412, 548]               0\n",
            "          Conv2d-188         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-189             [-1, 64, 1, 1]               0\n",
            "          Conv2d-190              [-1, 8, 1, 1]             520\n",
            "            ReLU-191              [-1, 8, 1, 1]               0\n",
            "          Conv2d-192             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-193             [-1, 64, 1, 1]               0\n",
            "         CALayer-194         [-1, 64, 412, 548]               0\n",
            "          Conv2d-195          [-1, 8, 412, 548]             520\n",
            "            ReLU-196          [-1, 8, 412, 548]               0\n",
            "          Conv2d-197          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-198          [-1, 1, 412, 548]               0\n",
            "         PALayer-199         [-1, 64, 412, 548]               0\n",
            "           Block-200         [-1, 64, 412, 548]               0\n",
            "          Conv2d-201         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-202         [-1, 64, 412, 548]               0\n",
            "          Conv2d-203         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-204             [-1, 64, 1, 1]               0\n",
            "          Conv2d-205              [-1, 8, 1, 1]             520\n",
            "            ReLU-206              [-1, 8, 1, 1]               0\n",
            "          Conv2d-207             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-208             [-1, 64, 1, 1]               0\n",
            "         CALayer-209         [-1, 64, 412, 548]               0\n",
            "          Conv2d-210          [-1, 8, 412, 548]             520\n",
            "            ReLU-211          [-1, 8, 412, 548]               0\n",
            "          Conv2d-212          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-213          [-1, 1, 412, 548]               0\n",
            "         PALayer-214         [-1, 64, 412, 548]               0\n",
            "           Block-215         [-1, 64, 412, 548]               0\n",
            "          Conv2d-216         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-217         [-1, 64, 412, 548]               0\n",
            "          Conv2d-218         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-219             [-1, 64, 1, 1]               0\n",
            "          Conv2d-220              [-1, 8, 1, 1]             520\n",
            "            ReLU-221              [-1, 8, 1, 1]               0\n",
            "          Conv2d-222             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-223             [-1, 64, 1, 1]               0\n",
            "         CALayer-224         [-1, 64, 412, 548]               0\n",
            "          Conv2d-225          [-1, 8, 412, 548]             520\n",
            "            ReLU-226          [-1, 8, 412, 548]               0\n",
            "          Conv2d-227          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-228          [-1, 1, 412, 548]               0\n",
            "         PALayer-229         [-1, 64, 412, 548]               0\n",
            "           Block-230         [-1, 64, 412, 548]               0\n",
            "          Conv2d-231         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-232         [-1, 64, 412, 548]               0\n",
            "          Conv2d-233         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-234             [-1, 64, 1, 1]               0\n",
            "          Conv2d-235              [-1, 8, 1, 1]             520\n",
            "            ReLU-236              [-1, 8, 1, 1]               0\n",
            "          Conv2d-237             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-238             [-1, 64, 1, 1]               0\n",
            "         CALayer-239         [-1, 64, 412, 548]               0\n",
            "          Conv2d-240          [-1, 8, 412, 548]             520\n",
            "            ReLU-241          [-1, 8, 412, 548]               0\n",
            "          Conv2d-242          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-243          [-1, 1, 412, 548]               0\n",
            "         PALayer-244         [-1, 64, 412, 548]               0\n",
            "           Block-245         [-1, 64, 412, 548]               0\n",
            "          Conv2d-246         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-247         [-1, 64, 412, 548]               0\n",
            "          Conv2d-248         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-249             [-1, 64, 1, 1]               0\n",
            "          Conv2d-250              [-1, 8, 1, 1]             520\n",
            "            ReLU-251              [-1, 8, 1, 1]               0\n",
            "          Conv2d-252             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-253             [-1, 64, 1, 1]               0\n",
            "         CALayer-254         [-1, 64, 412, 548]               0\n",
            "          Conv2d-255          [-1, 8, 412, 548]             520\n",
            "            ReLU-256          [-1, 8, 412, 548]               0\n",
            "          Conv2d-257          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-258          [-1, 1, 412, 548]               0\n",
            "         PALayer-259         [-1, 64, 412, 548]               0\n",
            "           Block-260         [-1, 64, 412, 548]               0\n",
            "          Conv2d-261         [-1, 64, 412, 548]          36,928\n",
            "            ReLU-262         [-1, 64, 412, 548]               0\n",
            "          Conv2d-263         [-1, 64, 412, 548]          36,928\n",
            "AdaptiveAvgPool2d-264             [-1, 64, 1, 1]               0\n",
            "          Conv2d-265              [-1, 8, 1, 1]             520\n",
            "            ReLU-266              [-1, 8, 1, 1]               0\n",
            "          Conv2d-267             [-1, 64, 1, 1]             576\n",
            "         Sigmoid-268             [-1, 64, 1, 1]               0\n",
            "         CALayer-269         [-1, 64, 412, 548]               0\n",
            "          Conv2d-270          [-1, 8, 412, 548]             520\n",
            "            ReLU-271          [-1, 8, 412, 548]               0\n",
            "          Conv2d-272          [-1, 1, 412, 548]               9\n",
            "         Sigmoid-273          [-1, 1, 412, 548]               0\n",
            "         PALayer-274         [-1, 64, 412, 548]               0\n",
            "           Block-275         [-1, 64, 412, 548]               0\n",
            "          Conv2d-276         [-1, 64, 412, 548]          36,928\n",
            "           Group-277         [-1, 64, 412, 548]               0\n",
            "AdaptiveAvgPool2d-278            [-1, 192, 1, 1]               0\n",
            "          Conv2d-279              [-1, 4, 1, 1]             772\n",
            "            ReLU-280              [-1, 4, 1, 1]               0\n",
            "          Conv2d-281            [-1, 192, 1, 1]             960\n",
            "         Sigmoid-282            [-1, 192, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 1,472,966\n",
            "Trainable params: 1,472,966\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 2.58\n",
            "Forward/backward pass size (MB): 13235.99\n",
            "Params size (MB): 5.62\n",
            "Estimated Total Size (MB): 13244.19\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OWIHI4esYhS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}