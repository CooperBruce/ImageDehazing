{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "modelSub.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abubakrsiddq/ImageDehazing/blob/main/models/FFA-net/ffa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "scrolled": false,
        "id": "N39U696_KnKD"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NetxtfKRKv7K",
        "outputId": "9bb71057-bbc3-443f-ab36-d5d2824ad634"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FE6nygwKnKd"
      },
      "source": [
        "# Preprocessing and loading of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQvDpNGaB_l"
      },
      "source": [
        "#ls drive/MyDrive/reside/archive/clear_images drive/MyDrive/reside/archive/haze  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "uk0gyj-8KnKe"
      },
      "source": [
        "# function to load the image in the form of tensors.\n",
        "\n",
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (412, 548), antialias = True)\n",
        "    img = img / 255.0\n",
        "    return img"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "vvpitygGKnKf"
      },
      "source": [
        "# function to get the path of individual image.\n",
        "\n",
        "def data_path(orig_img_path, hazy_img_path):\n",
        "    \n",
        "    train_img = []\n",
        "    val_img = []\n",
        "    \n",
        "    orig_img = glob.glob(orig_img_path + '/*.jpg')\n",
        "    n = len(orig_img)\n",
        "    random.shuffle(orig_img)\n",
        "    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\n",
        "    val_keys = orig_img[int(0.9*n):]\n",
        "    \n",
        "    split_dict = {}\n",
        "    for key in train_keys:\n",
        "        split_dict[key] = 'train'\n",
        "    for key in val_keys:\n",
        "        split_dict[key] = 'val'\n",
        "        \n",
        "    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\n",
        "    for img in hazy_img:\n",
        "        img_name = img.split('/')[-1]\n",
        "        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'\n",
        "        if (split_dict[orig_path] == 'train'):\n",
        "            train_img.append([img, orig_path])\n",
        "        else:\n",
        "            val_img.append([img, orig_path])\n",
        "            \n",
        "    return train_img, val_img"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "D-194d5sKnKg"
      },
      "source": [
        "# function to load tensor image data in batches.\n",
        "\n",
        "def dataloader(train_data, val_data, batch_size):\n",
        "    \n",
        "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    return train, val"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "2aU_zzDHKnKh"
      },
      "source": [
        "# function to display output.\n",
        "import cv2\n",
        "def display_img(model, hazy_img, orig_img):\n",
        "    \n",
        "    dehazed_img = model(hazy_img, training = True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    \n",
        "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
        "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()\n",
        "    #print(\"input image quality\",display_list)#niqe(cv2.imread(display_list[1])))\n",
        "    #print(\"input image quality\",niqe(cv2.imread(display_list[2])))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuypKuZZKnKi"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOzDIDpqjZBn"
      },
      "source": [
        "def default_conv(in_channels, out_channels, kernel_size, bias=True,activation='relu'):\n",
        "    return tf.keras.layers.Conv2D(out_channels, kernel_size,padding='same', use_bias=bias)\n",
        "    \n",
        "class PixAtLayer(tf.keras.Model):\n",
        "    def __init__(self, channel):\n",
        "        super(PixAtLayer, self).__init__()\n",
        "        self.pa = tf.keras.Sequential(\n",
        "                tf.keras.layers.Conv2D(channel // 8, 1, padding='valid',activation='relu'),\n",
        "                \n",
        "                tf.keras.layers.Conv2D( 1, 1,activation='sigmoid')        \n",
        "        )\n",
        "    def call(self, x):\n",
        "        y = self.pa(x)\n",
        "        return x * y\n",
        "\n",
        "class ChanAtLayer(tf.keras.Model):\n",
        "    def __init__(self, channel):\n",
        "        super(ChanAtLayer, self).__init__()\n",
        "        self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.ca = tf.keras.Sequential(\n",
        "                 tf.keras.layers.Conv2D(channel // 8, 1,activation='relu'),\n",
        "                \n",
        "                 tf.keras.layers.Conv2D(channel, 1, activation='sigmoid'))\n",
        "\n",
        "    def call(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.ca(y)\n",
        "        return x * y\n",
        "\n",
        "class Block_layer(tf.keras.Model):\n",
        "    def __init__(self, conv, dim, kernel_size,):\n",
        "        super(Block_layer, self).__init__()\n",
        "        self.conv1=conv(dim,dim, kernel_size, bias=True,activation='relu')\n",
        "        \n",
        "        self.conv2=conv(dim,dim, kernel_size, bias=True)\n",
        "        self.calayer=ChanAtLayer(dim)\n",
        "        self.palayer=PixAtLayer(dim)\n",
        "    def call(self, x):\n",
        "        res=self.conv1(x)\n",
        "        res=res+x \n",
        "        res=self.conv2(res)\n",
        "        res=self.calayer(res)\n",
        "        res=self.palayer(res)\n",
        "        res += x \n",
        "        return res\n",
        "\n",
        "class Group_layer(tf.keras.Model):\n",
        "    def __init__(self, conv, dim, kernel_size, blocks):\n",
        "        super(Group_layer, self).__init__()\n",
        "        modules = [ Block_layer(conv, dim, kernel_size)  for _ in range(blocks)]\n",
        "        modules.append(tf.keras.layers.Conv2D(dim, kernel_size))\n",
        "        self.gp = tf.keras.Sequential()\n",
        "        for lay in modules:\n",
        "          self.gp.add(lay)\n",
        "        \n",
        "    def call(self,input_tensor):\n",
        "        res = self.gp(input_tensor)\n",
        "        res +=input_tensor\n",
        "        return res\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTCX-CqzehI3"
      },
      "source": [
        "class FFAnet(tf.keras.Model):\n",
        "    def __init__(self,gps,blocks,conv=default_conv):\n",
        "        super(FFAnet, self).__init__()\n",
        "        # define all layers in init\n",
        "        # Layer of Block 1\n",
        "        self.gps=gps\n",
        "        self.dim=64\n",
        "        kernel_size=3\n",
        "        pre_process = [tf.keras.layers.Conv2D(self.dim, kernel_size)]\n",
        "        assert self.gps==3\n",
        "        self.g1= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g2= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        self.g3= Group_layer(conv, self.dim, kernel_size,blocks=blocks)\n",
        "        l=[\n",
        "            tf.keras.layers.GlobalAveragePooling2D(),\n",
        "            tf.keras.layers.Conv2D(self.dim//16,1,padding='valid'),\n",
        "            \n",
        "            tf.keras.layers.Conv2D(self.dim*self.gps, 1, padding='valid', use_bias=True,activation='sigmoid')\n",
        "            \n",
        "            ]\n",
        "       \n",
        "        self.ca=tf.keras.Sequential()\n",
        "        for lay in l:\n",
        "          self.ca.add(lay)\n",
        "        self.palayer=PixAtLayer(self.dim)\n",
        "\n",
        "        post_precess = [\n",
        "            conv(self.dim, self.dim, kernel_size),\n",
        "            conv(self.dim, 3, kernel_size)]\n",
        "\n",
        "        self.pre = tf.keras.Sequential(tf.keras.layers.Conv2D(self.dim, kernel_size))\n",
        "\n",
        "        self.post = tf.keras.Sequential()\n",
        "        for lay in post_precess:\n",
        "          self.post.add(lay)\n",
        "        \n",
        "    def call(self, input_tensor, training=False):\n",
        "        # forward pass: block 1 \n",
        "        x = self.pre(input_tensor)\n",
        "        res1=self.g1(x)\n",
        "        res2=self.g2(res1)\n",
        "        res3=self.g3(res2)\n",
        "        return res3\n",
        "        #w=self.ca(torch.cat([res1,res2,res3],dim=1))\n",
        "        #w=w.view(-1,self.gps,self.dim)[:,:,:,None,None]\n",
        "        #out=w[:,0,::]*res1+w[:,1,::]*res2+w[:,2,::]*res3\n",
        "        #out=self.palayer(out)\n",
        "        #x=self.post(out)\n",
        "        #return x + x1\n",
        "    def model(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "htg4Y_MW0Jfo",
        "outputId": "9d939216-04b6-4352-c48a-a7072ed08136"
      },
      "source": [
        "sub =FFAnet(gps=3,blocks=6)\n",
        "sub.model().summary()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-3601ba57af32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mFFAnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-cd5566bf4616>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m412\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m548\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-cd5566bf4616>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tensor, training)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# forward pass: block 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mres1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mres2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mres3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-33-636dfef7f6c7>:57 call  *\n        res = self.gp(input_tensor)\n    <ipython-input-20-d92c01dc8f4c>:42 call  *\n        res=self.calayer(res)\n    <ipython-input-20-d92c01dc8f4c>:27 call  *\n        y = self.ca(y)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__  **\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:238 assert_input_compatibility\n        '. Full shape received: ' +\n\n    TypeError: can only concatenate str (not \"Conv2D\") to str\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "HhB7n03AKnKo"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 10\n",
        "batch_size = 8\n",
        "k_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      \n",
        "regularizer = tf.keras.regularizers.L2(1e-4)\n",
        "b_init = tf.constant_initializer()\n",
        "\n",
        "train_data, val_data = data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze')\n",
        "train, val = dataloader(train_data, val_data, batch_size)\n",
        "\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "net = ModelSubClassing()\n",
        "\n",
        "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\n",
        "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_kg_hide-output": true,
        "id": "L7pz9bV9KnKr"
      },
      "source": [
        "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
        "        start_time_epoch = time.time()\n",
        "        start_time_step = time.time()\n",
        "        \n",
        "        # training loop\n",
        "        \n",
        "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "                train_logits = net(train_batch_haze, training = True)\n",
        "                #print(train_logits.shape)\n",
        "                loss = mean_squared_error(train_batch_orig, train_logits)\n",
        "\n",
        "            grads = tape.gradient(loss, net.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
        "\n",
        "            train_loss_tracker.update_state(train_batch_orig, train_logits)\n",
        "            if step == 0:\n",
        "                print('[', end='')\n",
        "            if step % 64 == 0:\n",
        "                print('=', end='')\n",
        "        \n",
        "        print(']', end='')\n",
        "        print('  -  ', end='')\n",
        "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
        "        \n",
        "        # validation loop\n",
        "        \n",
        "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
        "            val_logits = net(val_batch_haze, training = False)\n",
        "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
        "            \n",
        "            if step % 32 ==0:\n",
        "                display_img(net, val_batch_haze, val_batch_orig)\n",
        "        \n",
        "        print('  -  ', end='')\n",
        "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
        "        print('  -  ', end=' ')\n",
        "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
        "        \n",
        "        net.save('trained_model')           # save the model(variables, weights, etc)\n",
        "        train_loss_tracker.reset_states()\n",
        "        val_loss_tracker.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "sbnB0QNYKnKs",
        "outputId": "3cc91f0e-4874-48a1-9aef-879b642bd5e5"
      },
      "source": [
        "%%time\n",
        "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0 [="
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b0302f0e0cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-814522eb9084>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_haze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_orig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2574\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2575\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2577\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMg7MNzdkWCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fdc74a1-e20a-440a-9799-36088c824204"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 412, 548, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 412, 548, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 412, 548, 3)       1731      \n",
            "=================================================================\n",
            "Total params: 3,523\n",
            "Trainable params: 3,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CinhPC_5OSPB"
      },
      "source": [
        "## Learn"
      ]
    }
  ]
}