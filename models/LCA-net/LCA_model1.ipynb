{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gman-net-for-image-dehazing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "N39U696_KnKD"
      },
      "source": [
        "# [**LCA net**](https://arxiv.org/pdf/2008.10325v1.pdf) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI9UgPh4HaDt"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NetxtfKRKv7K",
        "outputId": "3abf4cc6-b052-4539-ce9e-51c76b2a44ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FE6nygwKnKd"
      },
      "source": [
        "# Preprocessing and loading of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQvDpNGaB_l"
      },
      "source": [
        "#ls drive/MyDrive/reside/archive/clear_images drive/MyDrive/reside/archive/haze  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk0gyj-8KnKe"
      },
      "source": [
        "# function to load the image in the form of tensors.\n",
        "\n",
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (412,548), antialias = True)\n",
        "    img = img / 255.0\n",
        "    return img"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvpitygGKnKf"
      },
      "source": [
        "# function to get the path of individual image.\n",
        "\n",
        "def data_path(orig_img_path, hazy_img_path):\n",
        "    \n",
        "    train_img = []\n",
        "    val_img = []\n",
        "    \n",
        "    orig_img = glob.glob(orig_img_path + '/*.jpg')\n",
        "    n = len(orig_img)\n",
        "    random.shuffle(orig_img)\n",
        "    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\n",
        "    val_keys = orig_img[int(0.9*n):]\n",
        "    \n",
        "    split_dict = {}\n",
        "    for key in train_keys:\n",
        "        split_dict[key] = 'train'\n",
        "    for key in val_keys:\n",
        "        split_dict[key] = 'val'\n",
        "        \n",
        "    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\n",
        "    for img in hazy_img:\n",
        "        img_name = img.split('/')[-1]\n",
        "        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'\n",
        "        if (split_dict[orig_path] == 'train'):\n",
        "            train_img.append([img, orig_path])\n",
        "        else:\n",
        "            val_img.append([img, orig_path])\n",
        "            \n",
        "    return train_img, val_img"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-194d5sKnKg"
      },
      "source": [
        "# function to load tensor image data in batches.\n",
        "\n",
        "def dataloader(train_data, val_data, batch_size):\n",
        "    \n",
        "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    return train, val"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aU_zzDHKnKh"
      },
      "source": [
        "# function to display output.\n",
        "\n",
        "def display_img(model, hazy_img, orig_img):\n",
        "    \n",
        "    dehazed_img = model(hazy_img, training = True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    \n",
        "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
        "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuypKuZZKnKi"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "id": "WRCns3vCKnKi"
      },
      "source": [
        "def LCAnet():\n",
        "    \n",
        "    inputs = tf.keras.Input(shape = [412,548, 3])     # height, width of input image changed because of error in output\n",
        "    conv = Conv2D(filters = 50, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',)(inputs)\n",
        "    poolLayer=AveragePooling2D(pool_size=(2,2))(conv)\n",
        "    conv1 = Conv2D(filters = 50, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu')(poolLayer)\n",
        "    poolLayer=AveragePooling2D(pool_size=(2,2))(conv1)  \n",
        "    #flat=Flatten()(poolLayer)\n",
        "    dens1=Dense(10,activation='relu')(poolLayer)\n",
        "    dens2=Dense(10,activation='relu')(dens1)\n",
        "    deconv1=Conv2DTranspose(50,kernel_size=(3,3),padding='same',activation='relu')(dens2)\n",
        "    upsamp1=UpSampling2D(size=(2,2))(deconv1)\n",
        "    deconv2=Conv2DTranspose(50,kernel_size=(3,3),padding='same',activation='relu')(upsamp1)\n",
        "    upsamp2=UpSampling2D(size=(2,2))(deconv2)\n",
        "    deconv3=Conv2DTranspose(3,kernel_size=(3,3),padding='same',activation='linear')(upsamp2)\n",
        "    output = deconv3\n",
        "    \n",
        "    return Model(inputs = inputs, outputs = output)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy0G_5bVtdjG",
        "outputId": "a0810797-56ef-47b2-8fd7-115dea7256ea"
      },
      "source": [
        "model=LCAnet()\n",
        "model.build([412,548,3])\n",
        "model.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 412, 548, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 412, 548, 50)      1400      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_4 (Average (None, 206, 274, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 206, 274, 50)      22550     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_5 (Average (None, 103, 137, 50)      0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 103, 137, 10)      510       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 103, 137, 10)      110       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTr (None, 103, 137, 50)      4550      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 206, 274, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTr (None, 206, 274, 50)      22550     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 412, 548, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTr (None, 412, 548, 3)       1353      \n",
            "=================================================================\n",
            "Total params: 53,023\n",
            "Trainable params: 53,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhB7n03AKnKo"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 10\n",
        "batch_size = 8\n",
        "k_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      \n",
        "regularizer = tf.keras.regularizers.L2(1e-4)\n",
        "b_init = tf.constant_initializer()\n",
        "\n",
        "#train_data, val_data = data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze')\n",
        "train_data, val_data = data_path(orig_img_path = './drive/MyDrive/dataset/clear_images', hazy_img_path = './drive/MyDrive/dataset/haze')\n",
        "train, val = dataloader(train_data, val_data, batch_size)\n",
        "\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "net = LCAnet()\n",
        "#net= tf.keras.models.load_model('/content/drive/MyDrive/nets/lca',compile=False)\n",
        "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\n",
        "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "id": "L7pz9bV9KnKr"
      },
      "source": [
        "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
        "        start_time_epoch = time.time()\n",
        "        start_time_step = time.time()\n",
        "        \n",
        "        # training loop\n",
        "        \n",
        "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "                train_logits = net(train_batch_haze, training = True)\n",
        "                loss = mean_squared_error(train_batch_orig, train_logits)\n",
        "\n",
        "            grads = tape.gradient(loss, net.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
        "\n",
        "            train_loss_tracker.update_state(train_batch_orig, train_logits)\n",
        "            if step == 0:\n",
        "                print('[', end='')\n",
        "            if step % 64 == 0:\n",
        "                print('=', end='')\n",
        "        \n",
        "        print(']', end='')\n",
        "        print('  -  ', end='')\n",
        "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
        "        \n",
        "        # validation loop\n",
        "        \n",
        "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
        "            val_logits = net(val_batch_haze, training = False)\n",
        "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
        "            \n",
        "            if step % 32 ==0:\n",
        "                display_img(net, val_batch_haze, val_batch_orig)\n",
        "        \n",
        "        print('  -  ', end='')\n",
        "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
        "        print('  -  ', end=' ')\n",
        "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
        "        \n",
        "        net.save('trained_model')           # save the model(variables, weights, etc)\n",
        "        train_loss_tracker.reset_states()\n",
        "        val_loss_tracker.reset_states()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "sbnB0QNYKnKs",
        "scrolled": true,
        "outputId": "55987aa5-76e8-49fd-99a2-ad55dcb76440"
      },
      "source": [
        "%%time\n",
        "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0 [="
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-b0302f0e0cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-0935632fb9e2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_haze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_orig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2574\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2575\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2577\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_24BaElOGWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3513971d-01eb-4bc4-baf1-204ca21dbc59"
      },
      "source": [
        "net.save('./drive/MyDrive/nets/lca')\n",
        "model=net\n",
        "model.build([512,512,3])\n",
        "model.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/nets/lca/assets\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 512, 512, 50)      1400      \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 256, 256, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 256, 256, 50)      22550     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 128, 128, 50)      0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128, 128, 10)      510       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128, 128, 10)      110       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 128, 128, 50)      4550      \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 256, 256, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 256, 256, 50)      22550     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 512, 512, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 512, 512, 3)       1353      \n",
            "=================================================================\n",
            "Total params: 53,023\n",
            "Trainable params: 53,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj2jEwFxKnKt",
        "scrolled": true
      },
      "source": [
        "import cv2\n",
        "def test_model(img_path, model):\n",
        "\n",
        "    \"\"\" \n",
        "    path : test image folder path\n",
        "    model : model instantiation\n",
        "    \n",
        "    DRIVE SHOULD BE MOUNTED\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    i=0\n",
        "\n",
        "\n",
        "    #plt.figure(figsize = (15,15))\n",
        "    test_img = glob.glob(img_path + '/*.jpg')\n",
        "    print(test_img)\n",
        "    test_img_slice = tf.data.Dataset.from_tensor_slices([img for img in test_img]).map(lambda x: load_image(x))\n",
        "    test = tf.data.Dataset.zip((test_img_slice)).batch(45)\n",
        "    \n",
        "    directory = '/content/drive/MyDrive/Test'\n",
        "    os.chdir(directory)\n",
        "    for img in test:\n",
        "        print(img.shape)\n",
        "        #pred = model(img)\n",
        "        #plt.imshow(pred)\n",
        "        #filename = 'Test-' + str(i) + '.jpg'\n",
        "        #cv2.imwrite(filename, pred) \n",
        "        i+=1\n",
        "    os.chdir('/content')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fhPfpFhQ5WJ"
      },
      "source": [
        "#test_net = tf.keras.models.load_model('trained_model', compile = False)\r\n",
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/lca',compile=False)\r\n",
        "\r\n",
        "#test_model('/content/drive/MyDrive/ohaze/hazy',new_model)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "id": "UUCDXhKnKnKu"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_gen(test_img_path,net):\n",
        "    \n",
        "    #test_img = glob.glob(test_img_path +'/*.jpg')\n",
        "    test_img=glob.glob('/content/drive/MyDrive/ohaze/hazy/*.jpg')\n",
        "    #random.shuffle(test_img)\n",
        "    i=1;\n",
        "    for img in test_img:\n",
        "        \n",
        "        img = tf.io.read_file(img)\n",
        "        img = tf.io.decode_jpeg(img, channels = 3)\n",
        "        \n",
        "        img = tf.image.resize(img, size = (412,548), antialias = True)\n",
        "        \n",
        "        img = img / 255.0\n",
        "        print(img.shape)\n",
        "        img = tf.expand_dims(img, axis = 0)      #transform input image from 3D to 4D ###\n",
        "        \n",
        "        dehaze = net(img)\n",
        "        \n",
        "        #plt.figure(figsize = (80, 80))\n",
        "        \n",
        "        #display_list = [img[0], dehaze[0]]       #make the first dimension zero\n",
        "        im=dehaze[0]\n",
        "        directory = '/content/drive/MyDrive/Test'\n",
        "        os.chdir(directory)\n",
        "        filename = str(i) + '_outdoor_gen.jpg'\n",
        "        #print(filename)\n",
        "        #cv2.imwrite(filename,im) \n",
        "        #plt.imsave(filename,im)\n",
        "        tf.keras.preprocessing.image.save_img(\n",
        "    filename, im)\n",
        "\n",
        "        os.chdir('/content')\n",
        "        i+=1;"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMg7MNzdkWCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786d006a-b727-4899-b906-5ce257a1ecd2"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/lca/trained_model',compile=False)\n",
        "\n",
        "evaluate_gen('/content/drive/MyDrive/ohaze/hazy/',new_model)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(412, 548, 3)\n",
            "1_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "2_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "3_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "4_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "5_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "6_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "7_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "8_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "9_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "10_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "11_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "12_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "13_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "14_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "15_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "16_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "17_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "18_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "19_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "20_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "21_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "22_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "23_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "24_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "25_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "26_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "27_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "28_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "29_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "30_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "31_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "32_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "33_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "34_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "35_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "36_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "37_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "38_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "39_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "40_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "41_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "42_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "43_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "44_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "45_outdoor_gen.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZJmVhXGkno_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33004f7-408d-4251-d6f7-3b38287a8570"
      },
      "source": [
        "ls"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtrained_model\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K5tsz-YNhVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fa4469-1b67-4e22-91fd-c332fcc3d4f6"
      },
      "source": [
        "ls ./trained_model"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/  saved_model.pb  \u001b[01;34mvariables\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na_h1-jvQXW9"
      },
      "source": [
        "cp -r trained_model/ /content/drive/MyDrive/nets/lca/trained_model"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX2tSDooQnhT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}