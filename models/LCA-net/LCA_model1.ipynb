{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gman-net-for-image-dehazing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "N39U696_KnKD"
      },
      "source": [
        "# [**LCA net**](https://arxiv.org/pdf/2008.10325v1.pdf) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI9UgPh4HaDt"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NetxtfKRKv7K",
        "outputId": "2fcd66c3-e930-4843-ffa1-c2ab8c4b9ab5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FE6nygwKnKd"
      },
      "source": [
        "# Preprocessing and loading of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQvDpNGaB_l"
      },
      "source": [
        "#ls drive/MyDrive/reside/archive/clear_images drive/MyDrive/reside/archive/haze  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk0gyj-8KnKe"
      },
      "source": [
        "# function to load the image in the form of tensors.\n",
        "\n",
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (412,548), antialias = True)\n",
        "    img = img / 255.0\n",
        "    return img"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvpitygGKnKf",
        "outputId": "955f2504-e897-473a-c714-bb4dc996f048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# function to get the path of individual image.\n",
        "'''\n",
        "def data_path(orig_img_path, hazy_img_path):\n",
        "    \n",
        "    train_img = []\n",
        "    val_img = []\n",
        "    \n",
        "    orig_img = glob.glob(orig_img_path + '/*.jpg')\n",
        "    n = len(orig_img)\n",
        "    random.shuffle(orig_img)\n",
        "    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\n",
        "    val_keys = orig_img[int(0.9*n):]\n",
        "    \n",
        "    split_dict = {}\n",
        "    for key in train_keys:\n",
        "        split_dict[key] = 'train'\n",
        "    for key in val_keys:\n",
        "        split_dict[key] = 'val'\n",
        "        \n",
        "    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\n",
        "    for img in hazy_img:\n",
        "        img_name = img.split('/')[-1]\n",
        "        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'\n",
        "        if (split_dict[orig_path] == 'train'):\n",
        "            train_img.append([img, orig_path])\n",
        "        else:\n",
        "            val_img.append([img, orig_path])\n",
        "            \n",
        "    return train_img, val_img\n",
        "    '''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef data_path(orig_img_path, hazy_img_path):\\n    \\n    train_img = []\\n    val_img = []\\n    \\n    orig_img = glob.glob(orig_img_path + '/*.jpg')\\n    n = len(orig_img)\\n    random.shuffle(orig_img)\\n    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\\n    val_keys = orig_img[int(0.9*n):]\\n    \\n    split_dict = {}\\n    for key in train_keys:\\n        split_dict[key] = 'train'\\n    for key in val_keys:\\n        split_dict[key] = 'val'\\n        \\n    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\\n    for img in hazy_img:\\n        img_name = img.split('/')[-1]\\n        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'\\n        if (split_dict[orig_path] == 'train'):\\n            train_img.append([img, orig_path])\\n        else:\\n            val_img.append([img, orig_path])\\n            \\n    return train_img, val_img\\n    \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlePdXgV9h90"
      },
      "source": [
        "def dataset_preposses(orig_path='/content/drive/MyDrive/dataset/clear_images',haze_path='/content/drive/MyDrive/dataset/haze',percentage=0.1,validation_size=64,test_size=64,seed_val=101):\n",
        "  '''\n",
        "  parameters:\n",
        "  orig_path(string): path of ground truth folder\n",
        "  haze_path(string): path of haze folder\n",
        "  percentage(float): percentage of dataset to load\n",
        "  validation_size(int): the no. of validation images\n",
        "  test_size(int): the no. of test images\n",
        "\n",
        "  returns:\n",
        "  haze_list,validation_list,test_list\n",
        "  '''\n",
        "  random.seed(seed_val)\n",
        "  pth=haze_path+'/*.jpg'\n",
        "  haze_path_list = glob.glob(pth)\n",
        "  orig_path_list=glob.glob(orig_path+'/*.jpg')\n",
        "  #print(orig_path_list)\n",
        "  random.shuffle(haze_path_list)\n",
        "  #print(haze_path_list)\n",
        "  haze_path_dict={}\n",
        "  haze_count_dict={}\n",
        "  haze_list=[]\n",
        "  no_per_set=int(percentage*35)\n",
        "  for i in haze_path_list:\n",
        "    name=i.split('/')[-1].split('_')[0]\n",
        "    if(int(name)>468):\n",
        "      try:\n",
        "        if(haze_count_dict[name]<no_per_set):\n",
        "          haze_path_dict[name].append(i)\n",
        "          \n",
        "          haze_count_dict[name]+=1;\n",
        "          \n",
        "      except KeyError:\n",
        "       \n",
        "        haze_path_dict[name]=[]\n",
        "        haze_path_dict[name].append(i)\n",
        "        haze_count_dict[name]=1\n",
        "    #print(haze_path_dict)\n",
        "  test_list=haze_path_list[-1*test_size:]\n",
        "  val_list=haze_path_list[-1*(validation_size+test_size):-1*test_size];\n",
        "\n",
        "  for (key,val) in haze_path_dict.items():\n",
        "    for i in val:\n",
        "      haze_list.append(i)\n",
        "  return haze_list,val_list,test_list\n",
        "\n",
        "\n",
        "def gen_dataset(ar):\n",
        "  '''\n",
        "  parameters\n",
        "  list of paths\n",
        "  return\n",
        "  list with gt attached \n",
        "  '''\n",
        "  orig_path='/content/drive/MyDrive/dataset/clear_images'\n",
        "  haze_pth='/content/drive/MyDrive/dataset/haze'\n",
        "  lst=[]\n",
        "  for i in ar:\n",
        "    name=i.split('/')[-1].split('_')[0]\n",
        "    pthlist=[i,orig_path+'/'+name+'.jpg']\n",
        "    lst.append(pthlist)\n",
        "  return lst\n",
        "\n",
        "def data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze'):\n",
        "  \n",
        "  (a,b,c)=dataset_preposses(orig_path=orig_img_path,haze_path=hazy_img_path)\n",
        "  a=gen_dataset(a)\n",
        "  b=gen_dataset(b)\n",
        "  return a,b\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-194d5sKnKg"
      },
      "source": [
        "# function to load tensor image data in batches.\n",
        "\n",
        "def dataloader(train_data, val_data, batch_size):\n",
        "    \n",
        "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    return train, val"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aU_zzDHKnKh"
      },
      "source": [
        "# function to display output.\n",
        "\n",
        "def display_img(model, hazy_img, orig_img):\n",
        "    \n",
        "    dehazed_img = model(hazy_img, training = True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    \n",
        "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
        "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuypKuZZKnKi"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "id": "WRCns3vCKnKi"
      },
      "source": [
        "def LCAnet():\n",
        "    \n",
        "    inputs = tf.keras.Input(shape = [412,548, 3])     # height, width of input image changed because of error in output\n",
        "    conv = Conv2D(filters = 50, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',)(inputs)\n",
        "    poolLayer=AveragePooling2D(pool_size=(2,2))(conv)\n",
        "    conv1 = Conv2D(filters = 50, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu')(poolLayer)\n",
        "    poolLayer=AveragePooling2D(pool_size=(2,2))(conv1)  \n",
        "    #flat=Flatten()(poolLayer)\n",
        "    dens1=Dense(10,activation='relu')(poolLayer)\n",
        "    dens2=Dense(10,activation='relu')(dens1)\n",
        "    deconv1=Conv2DTranspose(50,kernel_size=(3,3),padding='same',activation='relu')(dens2)\n",
        "    upsamp1=UpSampling2D(size=(2,2))(deconv1)\n",
        "    deconv2=Conv2DTranspose(50,kernel_size=(3,3),padding='same',activation='relu')(upsamp1)\n",
        "    upsamp2=UpSampling2D(size=(2,2))(deconv2)\n",
        "    deconv3=Conv2DTranspose(3,kernel_size=(3,3),padding='same',activation='linear')(upsamp2)\n",
        "    output = deconv3\n",
        "    \n",
        "    return Model(inputs = inputs, outputs = output)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy0G_5bVtdjG",
        "outputId": "44d4edbe-a1ac-4505-e338-148bc1cf96ce"
      },
      "source": [
        "model=LCAnet()\n",
        "model.build([412,548,3])\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 412, 548, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 412, 548, 50)      1400      \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 206, 274, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 206, 274, 50)      22550     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 103, 137, 50)      0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 103, 137, 10)      510       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 103, 137, 10)      110       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 103, 137, 50)      4550      \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 206, 274, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 206, 274, 50)      22550     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 412, 548, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 412, 548, 3)       1353      \n",
            "=================================================================\n",
            "Total params: 53,023\n",
            "Trainable params: 53,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhB7n03AKnKo"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 10\n",
        "batch_size = 8\n",
        "k_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      \n",
        "regularizer = tf.keras.regularizers.L2(1e-4)\n",
        "b_init = tf.constant_initializer()\n",
        "\n",
        "#train_data, val_data = data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze')\n",
        "train_data, val_data = data_path(orig_img_path = './drive/MyDrive/dataset/clear_images', hazy_img_path = './drive/MyDrive/dataset/haze')\n",
        "train, val = dataloader(train_data, val_data, batch_size)\n",
        "\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "net = LCAnet()\n",
        "#net= tf.keras.models.load_model('/content/drive/MyDrive/nets/lca',compile=False)\n",
        "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\n",
        "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "id": "L7pz9bV9KnKr"
      },
      "source": [
        "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
        "        start_time_epoch = time.time()\n",
        "        start_time_step = time.time()\n",
        "        \n",
        "        # training loop\n",
        "        \n",
        "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "                train_logits = net(train_batch_haze, training = True)\n",
        "                loss = mean_squared_error(train_batch_orig, train_logits)\n",
        "\n",
        "            grads = tape.gradient(loss, net.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
        "\n",
        "            train_loss_tracker.update_state(train_batch_orig, train_logits)\n",
        "            if step == 0:\n",
        "                print('[', end='')\n",
        "            if step % 64 == 0:\n",
        "                print('=', end='')\n",
        "        \n",
        "        print(']', end='')\n",
        "        print('  -  ', end='')\n",
        "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
        "        \n",
        "        # validation loop\n",
        "        \n",
        "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
        "            val_logits = net(val_batch_haze, training = False)\n",
        "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
        "            \n",
        "            if step % 32 ==0:\n",
        "                display_img(net, val_batch_haze, val_batch_orig)\n",
        "        \n",
        "        print('  -  ', end='')\n",
        "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
        "        print('  -  ', end=' ')\n",
        "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
        "        \n",
        "        net.save('trained_model')           # save the model(variables, weights, etc)\n",
        "        train_loss_tracker.reset_states()\n",
        "        val_loss_tracker.reset_states()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbnB0QNYKnKs",
        "scrolled": true,
        "outputId": "69059eb3-8ce9-4a7e-f529-5c1220681aa9"
      },
      "source": [
        "%%time\n",
        "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0 [="
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_24BaElOGWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3513971d-01eb-4bc4-baf1-204ca21dbc59"
      },
      "source": [
        "net.save('./drive/MyDrive/nets/lca')\n",
        "model=net\n",
        "model.build([512,512,3])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/nets/lca/assets\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 512, 512, 50)      1400      \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 256, 256, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 256, 256, 50)      22550     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 128, 128, 50)      0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128, 128, 10)      510       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128, 128, 10)      110       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 128, 128, 50)      4550      \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 256, 256, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 256, 256, 50)      22550     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 512, 512, 50)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 512, 512, 3)       1353      \n",
            "=================================================================\n",
            "Total params: 53,023\n",
            "Trainable params: 53,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj2jEwFxKnKt",
        "scrolled": true
      },
      "source": [
        "import cv2\n",
        "def test_model(img_path, model):\n",
        "\n",
        "    \"\"\" \n",
        "    path : test image folder path\n",
        "    model : model instantiation\n",
        "    \n",
        "    DRIVE SHOULD BE MOUNTED\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    i=0\n",
        "\n",
        "\n",
        "    #plt.figure(figsize = (15,15))\n",
        "    test_img = glob.glob(img_path + '/*.jpg')\n",
        "    print(test_img)\n",
        "    test_img_slice = tf.data.Dataset.from_tensor_slices([img for img in test_img]).map(lambda x: load_image(x))\n",
        "    test = tf.data.Dataset.zip((test_img_slice)).batch(45)\n",
        "    \n",
        "    directory = '/content/drive/MyDrive/Test'\n",
        "    os.chdir(directory)\n",
        "    for img in test:\n",
        "        print(img.shape)\n",
        "        #pred = model(img)\n",
        "        #plt.imshow(pred)\n",
        "        #filename = 'Test-' + str(i) + '.jpg'\n",
        "        #cv2.imwrite(filename, pred) \n",
        "        i+=1\n",
        "    os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fhPfpFhQ5WJ"
      },
      "source": [
        "#test_net = tf.keras.models.load_model('trained_model', compile = False)\r\n",
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/lca',compile=False)\r\n",
        "\r\n",
        "#test_model('/content/drive/MyDrive/ohaze/hazy',new_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "id": "UUCDXhKnKnKu"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "'''\n",
        "def evaluate_gen(test_img_path,net):\n",
        "    \n",
        "    #test_img = glob.glob(test_img_path +'/*.jpg')\n",
        "    test_img=glob.glob('/content/drive/MyDrive/ohaze/hazy/*.jpg')\n",
        "    #random.shuffle(test_img)\n",
        "    i=1;\n",
        "    for img in test_img:\n",
        "        \n",
        "        img = tf.io.read_file(img)\n",
        "        img = tf.io.decode_jpeg(img, channels = 3)\n",
        "        \n",
        "        img = tf.image.resize(img, size = (412,548), antialias = True)\n",
        "        \n",
        "        img = img / 255.0\n",
        "        print(img.shape)\n",
        "        img = tf.expand_dims(img, axis = 0)      #transform input image from 3D to 4D ###\n",
        "        \n",
        "        dehaze = net(img)\n",
        "        \n",
        "        #plt.figure(figsize = (80, 80))\n",
        "        \n",
        "        #display_list = [img[0], dehaze[0]]       #make the first dimension zero\n",
        "        im=dehaze[0]\n",
        "        directory = '/content/drive/MyDrive/Test'\n",
        "        os.chdir(directory)\n",
        "        filename = str(i) + '_outdoor_gen.jpg'\n",
        "        #print(filename)\n",
        "        #cv2.imwrite(filename,im) \n",
        "        #plt.imsave(filename,im)\n",
        "        tf.keras.preprocessing.image.save_img(\n",
        "    filename, im)\n",
        "\n",
        "        os.chdir('/content')\n",
        "        i+=1;\n",
        "        '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMg7MNzdkWCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786d006a-b727-4899-b906-5ce257a1ecd2"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/lca/trained_model',compile=False)\n",
        "\n",
        "evaluate_gen('/content/drive/MyDrive/ohaze/hazy/',new_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(412, 548, 3)\n",
            "1_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "2_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "3_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "4_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "5_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "6_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "7_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "8_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "9_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "10_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "11_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "12_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "13_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "14_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "15_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "16_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "17_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "18_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "19_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "20_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "21_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "22_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "23_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "24_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "25_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "26_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "27_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "28_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "29_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "30_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "31_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "32_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "33_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "34_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "35_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "36_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "37_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "38_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "39_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "40_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "41_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "42_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "43_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "44_outdoor_gen.jpg\n",
            "(412, 548, 3)\n",
            "45_outdoor_gen.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZJmVhXGkno_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33004f7-408d-4251-d6f7-3b38287a8570"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_gen(net):\n",
        "    n=0\n",
        "    _,_,c=dataset_preposses()\n",
        "    test_data=gen_dataset(c)\n",
        "    print(c)\n",
        "    for i in test_data:\n",
        "      hazy_img = tf.io.read_file(i[0])\n",
        "      hazy_img = tf.io.decode_jpeg(hazy_img, channels = 3)\n",
        "      hazy_img = tf.image.resize(hazy_img, size = (412,548), antialias = True)\n",
        "      gt_img = tf.io.read_file(i[1])\n",
        "      gt_img = tf.io.decode_jpeg(gt_img, channels = 3)\n",
        "      gt_img = tf.image.resize(gt_img, size = (412,548), antialias = True)\n",
        "\n",
        "      hazy_img =hazy_img / 255.0\n",
        "      gt_img=gt_img/255.0\n",
        "      hazy_img1 = tf.expand_dims(hazy_img, axis = 0)\n",
        "      #print(type(hazy_img))\n",
        "      dehaze = net(hazy_img1)\n",
        "      im=dehaze[0]\n",
        "      #print(im.shape)\n",
        "      directory = '/content/drive/MyDrive/demo/gt'\n",
        "      os.chdir(directory)\n",
        "      filename = str(n) + '_outdoor_gt.jpg'\n",
        "        #print(filename)\n",
        "        #cv2.imwrite(filename,im) \n",
        "        #plt.imsave(filename,im)\n",
        "      tf.keras.preprocessing.image.save_img( filename,gt_img)\n",
        "      \n",
        "      directory = '/content/drive/MyDrive/demo/gen'\n",
        "      os.chdir(directory)\n",
        "      filename = str(n) + '_outdoor_gen.jpg'\n",
        "      #print(filename)\n",
        "      tf.keras.preprocessing.image.save_img(filename, im)\n",
        "      \n",
        "\n",
        "      os.chdir('/content/drive/MyDrive/demo/haze')\n",
        "      filename = str(n) + '_outdoor_haze.jpg'\n",
        "      #print(filename)\n",
        "      tf.keras.preprocessing.image.save_img(filename,hazy_img)\n",
        "      n+=1;\n",
        "      print(n,end=' ')\n",
        "      #print(i[0])\n",
        "      #print(i[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtrained_model\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K5tsz-YNhVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fa4469-1b67-4e22-91fd-c332fcc3d4f6"
      },
      "source": [
        "ls ./trained_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34massets\u001b[0m/  saved_model.pb  \u001b[01;34mvariables\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na_h1-jvQXW9"
      },
      "source": [
        "cp -r trained_model/ /content/drive/MyDrive/nets/lca/trained_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX2tSDooQnhT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}