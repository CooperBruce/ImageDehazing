{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestNet_with_new_loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsKMH5AxGE4/Zg+0F76IZc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abubakrsiddq/ImageDehazing/blob/main/models/custom_loss/TestNet_with_new_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJt-jM0EGHcW"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from math import log10, sqrt\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEStXK2HGTpJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10qoMTIsGWVg"
      },
      "source": [
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (412, 548), antialias = True)\n",
        "    img = img / 255.0\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7YpgZqsGZ32"
      },
      "source": [
        "def dataset_preposses(orig_path='/content/drive/MyDrive/dataset/clear_images',haze_path='/content/drive/MyDrive/dataset/haze',percentage=0.3,validation_size=64,test_size=64,seed_val=101):\n",
        "  '''\n",
        "  parameters:\n",
        "  orig_path(string): path of ground truth folder\n",
        "  haze_path(string): path of haze folder\n",
        "  percentage(float): percentage of dataset to load\n",
        "  validation_size(int): the no. of validation images\n",
        "  test_size(int): the no. of test images\n",
        "\n",
        "  returns:\n",
        "  haze_list,validation_list,test_list\n",
        "  '''\n",
        "  random.seed(seed_val)\n",
        "  pth=haze_path+'/*.jpg'\n",
        "  haze_path_list = glob.glob(pth)\n",
        "  orig_path_list=glob.glob(orig_path+'/*.jpg')\n",
        "  #print(orig_path_list)\n",
        "  random.shuffle(haze_path_list)\n",
        "  #print(haze_path_list)\n",
        "  haze_path_dict={}\n",
        "  haze_count_dict={}\n",
        "  haze_list=[]\n",
        "  no_per_set=int(percentage*35)\n",
        "  for i in haze_path_list:\n",
        "    name=i.split('/')[-1].split('_')[0]\n",
        "    if(int(name)>468):\n",
        "      try:\n",
        "        if(haze_count_dict[name]<no_per_set):\n",
        "          haze_path_dict[name].append(i)\n",
        "          \n",
        "          haze_count_dict[name]+=1;\n",
        "          \n",
        "      except KeyError:\n",
        "       \n",
        "        haze_path_dict[name]=[]\n",
        "        haze_path_dict[name].append(i)\n",
        "        haze_count_dict[name]=1\n",
        "    #print(haze_path_dict)\n",
        "  test_list=haze_path_list[-1*test_size:]\n",
        "  val_list=haze_path_list[-1*(validation_size+test_size):-1*test_size];\n",
        "\n",
        "  for (key,val) in haze_path_dict.items():\n",
        "    for i in val:\n",
        "      haze_list.append(i)\n",
        "  return haze_list,val_list,test_list\n",
        "\n",
        "\n",
        "def gen_dataset(ar):\n",
        "  '''\n",
        "  parameters\n",
        "  list of paths\n",
        "  return\n",
        "  list with gt attached \n",
        "  '''\n",
        "  orig_path='/content/drive/MyDrive/dataset/clear_images'\n",
        "  haze_pth='/content/drive/MyDrive/dataset/haze'\n",
        "  lst=[]\n",
        "  for i in ar:\n",
        "    name=i.split('/')[-1].split('_')[0]\n",
        "    pthlist=[i,orig_path+'/'+name+'.jpg']\n",
        "    lst.append(pthlist)\n",
        "  return lst\n",
        "\n",
        "def data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze'):\n",
        "  \n",
        "  (a,b,c)=dataset_preposses(orig_path=orig_img_path,haze_path=hazy_img_path)\n",
        "  a=gen_dataset(a)\n",
        "  b=gen_dataset(b)\n",
        "  return a,b\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7LkfY76Gfgy"
      },
      "source": [
        "def dataloader(train_data, val_data, batch_size):\n",
        "    \n",
        "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    return train, val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bye-i7pGiO-"
      },
      "source": [
        "def display_img(model, hazy_img, orig_img):\n",
        "    \n",
        "    dehazed_img = model(hazy_img, training = True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    \n",
        "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
        "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNTmbcTHGtZC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8lvxmXiKx0D"
      },
      "source": [
        "# **network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srej_gE4Gtbj"
      },
      "source": [
        "\n",
        "\n",
        "def  custom_Loss():\n",
        "    \n",
        "   \n",
        "    \n",
        "    inputs = tf.keras.Input(shape = [413,550,3])\n",
        "    #pad=tf.keras.layers.ZeroPadding2D(padding=(1, 1))(inputs)\n",
        "\n",
        "    conv1 = Conv2D(input_shape = (413, 550, 3), filters = 3, kernel_size = 1, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))(inputs)\n",
        "    \n",
        "    conv2 = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))(conv1)\n",
        "    concat1 = tf.concat([conv1,conv2], axis = -1)\n",
        "    \n",
        "    conv3 = Conv2D(filters = 3, kernel_size = 5, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))(concat1)\n",
        "    concat2 = tf.concat([conv2,conv3], axis = -1)\n",
        "    \n",
        "    conv4 = Conv2D(filters = 3, kernel_size = 7, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))(concat2)\n",
        "    concat3 = tf.concat([conv1,conv2,conv3,conv4], axis = -1)\n",
        "    \n",
        "    conv5 = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))(concat3)\n",
        "    K = conv5\n",
        "    output = ReLU(max_value = 1.0)(tf.math.multiply(K,inputs) - K + 1.0)\n",
        "    #output1=tf.image.resize_with_crop_or_pad(output1, 412, 548)\n",
        "    #output=tf.image.resize(output1, size = (413, 550), antialias = True)\n",
        "    #model = Model(inputs = x, outputs = output)\n",
        "    \n",
        "    return Model(inputs = inputs, outputs = output)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNT0WSxTLL40"
      },
      "source": [
        "model= custom_Loss()\n",
        "model.build([412,548,3])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I3VLf5aHwNB"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import time\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "class Node(object):\n",
        "    def __init__(self,x,y,value):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.value = value\n",
        "\n",
        "    def printInfo(self):\n",
        "        print('%s:%s:%s' %(self.x,self.y,self.value))\n",
        "\n",
        "\n",
        "\n",
        "#check if image shape is fine i.e. there are 3 channels\n",
        "#returns min of three channels\n",
        "def getMinChannel(img):\n",
        "    '''gets min in val in differnt channel\n",
        "    Parameters:\n",
        "        img(numpy array): input image\n",
        "    Returns:\n",
        "        min in three channels'''\n",
        "    if len(img.shape)==3 and img.shape[2]==3:\n",
        "        pass\n",
        "    else:\n",
        "        print(\"bad image shape, input must be color image\")\n",
        "        return None\n",
        "    \n",
        "    return np.min(img, axis=2)\n",
        "\n",
        "def getDarkChannel(img,blockSize = 3):\n",
        "    '''\n",
        "    Gets dark channel\n",
        "    Parameters:\n",
        "        image(numpy array): Input image\n",
        "        blockSize(int):neighbourhood Refered to as omega in paper\n",
        "    Return:\n",
        "        image:Dark channel only one channel\n",
        "    '''\n",
        "    \n",
        "    if len(img.shape)==2:\n",
        "        pass\n",
        "    else:\n",
        "        print(\"bad image shape, input image must be two demensions\")\n",
        "        return None\n",
        "\n",
        "    \n",
        "    if blockSize % 2 == 0 or blockSize < 3:\n",
        "        print('blockSize is not odd or too small')\n",
        "        return None\n",
        "\n",
        "    \n",
        "    A = int((blockSize-1)/2) #Define increments around centre of the block\n",
        "\n",
        "    #New height and new width\n",
        "    H = img.shape[0] + blockSize - 1\n",
        "    W = img.shape[1] + blockSize - 1\n",
        "\n",
        "    #define padding\n",
        "    imgMiddle = 255 * np.ones((H,W))    \n",
        "\n",
        "    imgMiddle[A:H-A, A:W-A] = img\n",
        "    \n",
        "    imgDark = np.zeros_like(img, np.uint8)    \n",
        "    \n",
        "    localMin = 255\n",
        "    #define neighbourhood\n",
        "    for i in range(A, H-A):\n",
        "        for j in range(A, W-A):\n",
        "            x = range(i-A, i+A+1)\n",
        "            y = range(j-A, j+A+1)\n",
        "            #defines darkest pix in neighbourhood\n",
        "            imgDark[i-A,j-A] = np.min(imgMiddle[x,y])                            \n",
        "            \n",
        "    return imgDark\n",
        "\n",
        "def getAtomsphericLight(darkChannel,img,meanMode = False, percent = 0.001):\n",
        "    '''\n",
        "    Gets estimate for for factor A in transmission map\n",
        "    Parameters:\n",
        "        darkChannel(1-D numpy array): Dark channel obtained from getDarkChannel()\n",
        "        img(3-d numpy array): input image\n",
        "        percent(float): percent of pixels to be considered for A calculation\n",
        "    Returns atmosphericLight(float): value of term A\n",
        "    '''\n",
        "    imgGray = getMinChannel(img)\n",
        "    imgDark = getDarkChannel(imgGray, blockSize = 15)\n",
        "    \n",
        "\n",
        "    size = darkChannel.shape[0]*darkChannel.shape[1]\n",
        "    height = darkChannel.shape[0]\n",
        "    width = darkChannel.shape[1]\n",
        "\n",
        "    nodes = []\n",
        "\n",
        "    #list of pixel location and darkchannel intensity location\n",
        "    for i in range(0,height):\n",
        "        for j in range(0,width):\n",
        "            oneNode = Node(i,j,darkChannel[i,j])\n",
        "            nodes.append(oneNode)\t\n",
        "\n",
        "    #sort nodes in descending order of dark channel intensity\n",
        "    nodes = sorted(nodes, key = lambda node: node.value,reverse = True)\n",
        "\n",
        "    atomsphericLight = 0\n",
        "\n",
        "    # top value of img as atmospheric light\n",
        "    if int(percent*size) == 0:\n",
        "        for i in range(0,3):\n",
        "            if img[nodes[0].x,nodes[0].y,i] > atomsphericLight:\n",
        "                atomsphericLight = img[nodes[0].x,nodes[0].y,i]\n",
        "        return atomsphericLight\n",
        "\n",
        "    \n",
        "    if meanMode:\n",
        "        sum = 0\n",
        "        for i in range(0,int(percent*size)):\n",
        "            for j in range(0,3):\n",
        "                sum = sum + img[nodes[i].x,nodes[i].y,j]\n",
        "        atomsphericLight = int(sum/(int(percent*size)*3))\n",
        "        return atomsphericLight\n",
        "\n",
        "   \n",
        "    for i in range(0,int(percent*size)):\n",
        "        for j in range(0,3):\n",
        "            if img[nodes[i].x,nodes[i].y,j] > atomsphericLight:\n",
        "                atomsphericLight = img[nodes[i].x,nodes[i].y,j]\n",
        "    return atomsphericLight"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND43J41TLSzZ"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 5\n",
        "batch_size = 8\n",
        "\n",
        "\n",
        "#train_data, val_data = data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze')\n",
        "train_data, val_data = data_path(orig_img_path = './drive/MyDrive/dataset/clear_images', hazy_img_path = './drive/MyDrive/dataset/haze')\n",
        "train, val = dataloader(train_data, val_data, batch_size)\n",
        "\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "net = custom_Loss()\n",
        "#net= tf.keras.models.load_model('/content/drive/MyDrive/nets/test_custom_loss_net',compile=False)\n",
        "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\n",
        "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqftUl4eGtp7"
      },
      "source": [
        "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
        "        start_time_epoch = time.time()\n",
        "        start_time_step = time.time()\n",
        "        \n",
        "        # training loop\n",
        "        \n",
        "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "                train_logits = net(train_batch_haze, training = True)\n",
        "                loss = mean_squared_error(train_batch_orig, train_logits)\n",
        "\n",
        "            grads = tape.gradient(loss, net.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
        "\n",
        "            train_loss_tracker.update_state(train_batch_orig, train_logits)\n",
        "            if step == 0:\n",
        "                print('[', end='')\n",
        "            if step % 64 == 0:\n",
        "                print('=', end='')\n",
        "        \n",
        "        print(']', end='')\n",
        "        print('  -  ', end='')\n",
        "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
        "        \n",
        "        # validation loop\n",
        "        \n",
        "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
        "            val_logits = net(val_batch_haze, training = False)\n",
        "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
        "            \n",
        "            if step % 32 ==0:\n",
        "                display_img(net, val_batch_haze, val_batch_orig)\n",
        "        \n",
        "        print('  -  ', end='')\n",
        "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
        "        print('  -  ', end=' ')\n",
        "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
        "        \n",
        "        net.save('trained_model')           # save the model(variables, weights, etc)\n",
        "        train_loss_tracker.reset_states()\n",
        "        val_loss_tracker.reset_states()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxobCF_TGvMW"
      },
      "source": [
        "\n",
        "\n",
        "%%time\n",
        "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6DS2JJKG1nr"
      },
      "source": [
        "net.save('./drive/MyDrive/nets/test_custom_loss_net')\n",
        "model=net\n",
        "#model.build([412,548,3])\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XxulTP8G6vZ"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def msee(imageA, imageB):\n",
        "\t# the 'Mean Squared Error' between the two images is the\n",
        "\t# sum of the squared difference between the two images;\n",
        "\t# NOTE: the two images must have the same dimension\n",
        "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
        "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
        "\t\n",
        "\t# return the MSE, the lower the error, the more \"similar\"\n",
        "\t# the two images are\n",
        "\treturn err\n",
        "def compare_images(imageA, imageB):\n",
        "  # compute the mean squared error and structural similarity\n",
        "  # index for the images\n",
        "  m = msee(imageA, imageB)\n",
        "  s = ssim(imageA, imageB,multichannel=True)\n",
        "  return s\n",
        "  #s=tf.image.ssim(imageA, imageB, max_val=255, filter_size=11,filter_sigma=1.5, k1=0.01, k2=0.03)\n",
        "def find_psnr(imageA,imageB):\n",
        "   return cv2.PSNR(imageA,imageB)\n",
        "\n",
        "def evaluate_gen(net):\n",
        "    \n",
        "    #test_img = glob.glob(test_img_path +'/*.jpg')\n",
        "    test_img=glob.glob('/content/drive/MyDrive/Final_compare/HAZY/*.jpg')\n",
        "    \n",
        "    #random.shuffle(test_img)\n",
        "    i=1;\n",
        "    for img in test_img:\n",
        "        \n",
        "        img = tf.io.read_file(img)\n",
        "        img = tf.io.decode_jpeg(img, channels = 3)\n",
        "        \n",
        "        img = tf.image.resize(img, size = (412,548), antialias = True)\n",
        "        \n",
        "        img = img / 255.0\n",
        "        print(i,end=\" \")\n",
        "        img = tf.expand_dims(img, axis = 0)      #transform input image from 3D to 4D ###\n",
        "        \n",
        "        dehaze = net(img)\n",
        "        dehaze=tf.image.resize(dehaze, size = (413,550), antialias = True)\n",
        "        #plt.figure(figsize = (80, 80))\n",
        "        \n",
        "        #display_list = [img[0], dehaze[0]]       #make the first dimension zero\n",
        "        im=dehaze[0]\n",
        "        directory = '/content/drive/MyDrive/Final_compare/test_custom_loss_net'\n",
        "        \n",
        "        os.chdir(directory)\n",
        "        filename = str(i) + '_outdoor_gen.jpg'\n",
        "        #print(filename)\n",
        "        #cv2.imwrite(filename,im) \n",
        "        #plt.imsave(filename,im)\n",
        "        tf.keras.preprocessing.image.save_img(filename,im)\n",
        "\n",
        "        os.chdir('/content')\n",
        "        i+=1;\n",
        "    orig_img_path='/content/drive/MyDrive/Final_compare/GT'\n",
        "    orig_img = glob.glob(orig_img_path + '/*.jpg')\n",
        "    orig_img.sort()\n",
        "\n",
        "    test_img_path='/content/drive/MyDrive/Final_compare/test_custom_loss_net'\n",
        "    \n",
        "    test_img = glob.glob(test_img_path + '/*.jpg')\n",
        "    test_img.sort()\n",
        "\n",
        "\n",
        "    psnr_val=0;ssim_val=0;\n",
        "    n=len(orig_img)\n",
        "    for i in range(len(orig_img)):\n",
        "      os.chdir(orig_img_path)\n",
        "      original = cv2.imread(orig_img[i]) \n",
        "      #original=tf.image.resize_with_crop_or_pad(original, 400, 520)\n",
        "      original = original[3:-4,3:-4,]\n",
        "      os.chdir(test_img_path)\n",
        "      hazy = cv2.imread(test_img[i]) \n",
        "      #hazy=tf.image.resize_with_crop_or_pad(hazy, 400, 520)\n",
        "      hazy=hazy[3:-4,3:-4]\n",
        "      psnr_val+=find_psnr(original, hazy)\n",
        "      ssim_val+=compare_images(original, hazy)\n",
        "      #print(i,end=\" \")\n",
        "    total_psnr=psnr_val/n\n",
        "    total_ssim=ssim_val/n\n",
        "    print(\"\\n psnr=\",total_psnr)\n",
        "    print(\"ssim=\",total_ssim)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDIcNhLTHIQP"
      },
      "source": [
        "\n",
        "\n",
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/test_custom_loss_net',compile=False)\n",
        "\n",
        "\n",
        "evaluate_gen(new_model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP10YhKaHVB9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}