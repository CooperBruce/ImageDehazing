{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestNet_with_new_loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNarIwDuJGkI1ZUttECGziH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abubakrsiddq/ImageDehazing/blob/main/models/custom_loss/unet_dehaze_blocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6XauwyS52Sc"
      },
      "source": [
        "# U NET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJt-jM0EGHcW"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from math import log10, sqrt\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEStXK2HGTpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc185f8-e788-4016-d902-33a06eab16f2"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10qoMTIsGWVg"
      },
      "source": [
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (512, 512), antialias = True)\n",
        "    img = img / 255.0\n",
        "    return img"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7YpgZqsGZ32"
      },
      "source": [
        "def dataset_preposses(orig_path='/content/drive/MyDrive/dataset/clear_images',haze_path='/content/drive/MyDrive/dataset/haze',percentage=0.1,validation_size=64,test_size=64,seed_val=900):\n",
        "  '''\n",
        "  parameters:\n",
        "  orig_path(string): path of ground truth folder\n",
        "  haze_path(string): path of haze folder\n",
        "  percentage(float): percentage of dataset to load\n",
        "  validation_size(int): the no. of validation images\n",
        "  test_size(int): the no. of test images\n",
        "\n",
        "  returns:\n",
        "  haze_list,validation_list,test_list\n",
        "  '''\n",
        "  random.seed(seed_val)\n",
        "  pth=haze_path+'/*.jpg'\n",
        "  haze_path_list = glob.glob(pth)\n",
        "  orig_path_list=glob.glob(orig_path+'/*.jpg')\n",
        "  #print(orig_path_list)\n",
        "  random.shuffle(haze_path_list)\n",
        "  #print(haze_path_list)\n",
        "  haze_path_dict={}\n",
        "  haze_count_dict={}\n",
        "  haze_list=[]\n",
        "  no_per_set=int(percentage*35)\n",
        "  for i in haze_path_list:\n",
        "    name=i.split('/')[-1].split('_')[0]\n",
        "    if(int(name)>468):\n",
        "      try:\n",
        "        if(haze_count_dict[name]<no_per_set):\n",
        "          haze_path_dict[name].append(i)\n",
        "          \n",
        "          haze_count_dict[name]+=1;\n",
        "          \n",
        "      except KeyError:\n",
        "       \n",
        "        haze_path_dict[name]=[]\n",
        "        haze_path_dict[name].append(i)\n",
        "        haze_count_dict[name]=1\n",
        "    #print(haze_path_dict)\n",
        "  test_list=haze_path_list[-1*test_size:]\n",
        "  val_list=haze_path_list[-1*(validation_size+test_size):-1*test_size];\n",
        "\n",
        "  for (key,val) in haze_path_dict.items():\n",
        "    for i in val:\n",
        "      haze_list.append(i)\n",
        "  return haze_list,val_list,test_list\n",
        "\n",
        "\n",
        "def gen_dataset(ar):\n",
        "  '''\n",
        "  parameters\n",
        "  list of paths\n",
        "  return\n",
        "  list with gt attached \n",
        "  '''\n",
        "  orig_path='/content/drive/MyDrive/dataset/clear_images'\n",
        "  haze_pth='/content/drive/MyDrive/dataset/haze'\n",
        "  lst=[]\n",
        "  for i in ar:\n",
        "    name=i.split('/')[-1].split('_')[0]\n",
        "    pthlist=[i,orig_path+'/'+name+'.jpg']\n",
        "    lst.append(pthlist)\n",
        "  return lst\n",
        "\n",
        "def data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze'):\n",
        "  \n",
        "  (a,b,c)=dataset_preposses(orig_path=orig_img_path,haze_path=hazy_img_path)\n",
        "  a=gen_dataset(a)\n",
        "  b=gen_dataset(b)\n",
        "  return a,b\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7LkfY76Gfgy"
      },
      "source": [
        "def dataloader(train_data, val_data, batch_size):\n",
        "    print(len(train_data))\n",
        "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    #print(np.stack(list(train)).shape)\n",
        "    #train=np.stack(list(train));val=np.stack(list(val))\n",
        "    return train,val"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bye-i7pGiO-"
      },
      "source": [
        "def display_img(model, hazy_img, orig_img):\n",
        "    \n",
        "    dehazed_img = model(hazy_img, training = True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    \n",
        "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
        "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNTmbcTHGtZC"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8lvxmXiKx0D"
      },
      "source": [
        "# **network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTSdPEAFJ3mz"
      },
      "source": [
        "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
        "    return tf.keras.layers.Conv2D(out_channels, kernel_size,padding='same', use_bias=bias)\n",
        "    \n",
        "class PixAtLayer(tf.keras.Model):\n",
        "    def __init__(self, channel):\n",
        "        super(PixAtLayer, self).__init__()\n",
        "        self.pa = tf.keras.Sequential()\n",
        "        self.pa.add(tf.keras.layers.Conv2D(channel // 8, 1, padding='valid',activation='relu'))\n",
        "        self.pa.add(tf.keras.layers.Conv2D( 1, 1,activation='sigmoid'))\n",
        "    def call(self, x):\n",
        "        y = self.pa(x)\n",
        "        #return y\n",
        "        return x * y\n",
        "\n",
        "    def model(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "def adapavgpooling(x,outsize):\n",
        "    x_shape=tf.keras.backend.int_shape(x)\n",
        "    batchsize1,dim1,dim2,channels1=x_shape\n",
        "    stride=np.floor(dim1/outsize).astype(np.int32)\n",
        "    kernels=dim1-(outsize-1)*stride\n",
        "    adpooling=tf.keras.layers.AveragePooling2D(pool_size=(kernels,kernels),strides=(stride,stride))(x)\n",
        "    \n",
        "    return adpooling\n",
        "\n",
        "class ChanAtLayer(tf.keras.Model):\n",
        "  def __init__(self, channel):\n",
        "      super(ChanAtLayer, self).__init__()\n",
        "      #self.avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "      self.ca = tf.keras.Sequential()\n",
        "      self.ca.add(tf.keras.layers.Conv2D(channel // 8, 1,activation='relu'))\n",
        "      self.ca.add(tf.keras.layers.Conv2D(channel, 1, activation='sigmoid'))\n",
        "\n",
        "  def call(self, x):\n",
        "      y = adapavgpooling(x,1)\n",
        "      y = self.ca(y)\n",
        "      #return y\n",
        "      return x * y\n",
        "\n",
        "  def model(self):\n",
        "        x = Input(shape = (412, 548, 64))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class dehazenet_attention(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(dehazenet_attention, self).__init__()\n",
        "    self.conv1 = tf.keras.layers.Conv2D(input_shape = (412, 548, 3), filters = 3, kernel_size = 1, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))\n",
        "    self.conv2 = tf.keras.layers.Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))\n",
        "    self.conv3 = tf.keras.layers.Conv2D(filters = 3, kernel_size = 5, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))\n",
        "    self.conv4 = tf.keras.layers.Conv2D(filters = 3, kernel_size = 7, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))\n",
        "    self.conv5 = tf.keras.layers.Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))\n",
        "    self.conv6 = tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))\n",
        "    self.conv7 = tf.keras.layers.Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', use_bias = True,\n",
        "                   kernel_initializer = tf.random_normal_initializer(stddev = 0.02), kernel_regularizer = tf.keras.regularizers.l2(1e-2))\n",
        "    self.pa=PixAtLayer(64)\n",
        "    self.ca=ChanAtLayer(64)\n",
        "  def call(self, input_tensor, training=False):\n",
        "      x1=self.conv1(input_tensor)\n",
        "      x2=self.conv2(x1)\n",
        "      concat1 = tf.concat([x1,x2], axis = -1)\n",
        "      x3=self.conv3(concat1)\n",
        "      concat2 = tf.concat([x2,x3], axis = -1)\n",
        "      x4=self.conv4(concat2)\n",
        "      concat3 = tf.concat([x1,x2,x3,x4], axis = -1)\n",
        "      K=self.conv5(concat3)\n",
        "      output1 = ReLU(max_value = 1.0)(tf.math.multiply(K,input_tensor) - K + 1.0)\n",
        "      #x=self.conv6(output1)\n",
        "      x=self.pa(output1)\n",
        "      x=self.conv6(x)\n",
        "      x=self.ca(x)\n",
        "      output=self.conv7(x)\n",
        "      return output\n",
        "\n",
        "  def model(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "  def build_graph(self):\n",
        "        x = Input(shape=(412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhhVqRUIKegW"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srej_gE4Gtbj"
      },
      "source": [
        "start_neurons=16\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class unet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "      super(unet, self).__init__()\n",
        "      self.input_layer=tf.keras.layers.experimental.preprocessing.Resizing(512, 512, interpolation=\"bilinear\")\n",
        "      self.conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.conv1_1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.pool1 = MaxPooling2D((2, 2))\n",
        "      self.pool1_1 = Dropout(0.25)\n",
        "\n",
        "\n",
        "      self.conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.conv2_2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.pool2 = MaxPooling2D((2, 2))\n",
        "      self.pool2_2 = Dropout(0.5)\n",
        "\n",
        "\n",
        "      self.conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.conv3_3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.pool3 = MaxPooling2D((2, 2))\n",
        "      self.pool3_3 = Dropout(0.5)\n",
        "\n",
        "\n",
        "      self.conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.conv4_4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.pool4 = MaxPooling2D((2, 2))\n",
        "      self.pool4_4 = Dropout(0.5)\n",
        "      \n",
        "      self.convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.convm_1 = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "\n",
        "\n",
        "      self.deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")\n",
        "      self.uconv4_1 = Dropout(0.5)\n",
        "      self.uconv4_2 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.uconv4_3 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "\n",
        "      self.deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")\n",
        "      self.uconv3_1 = Dropout(0.5)\n",
        "      self.uconv3_2 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.uconv3_3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "\n",
        "      self.deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")\n",
        "      self.uconv2_1 = Dropout(0.5)\n",
        "      self.uconv2_2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.uconv2_3 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "\n",
        "      self.deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")\n",
        "      self.uconv1_1 = Dropout(0.5)\n",
        "      self.uconv1_2 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      self.uconv1_3 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")\n",
        "      \n",
        "      self.output_layer = Conv2D(3, (1,1), padding=\"same\", activation=\"sigmoid\")\n",
        "      self.output_=tf.keras.layers.experimental.preprocessing.Resizing(412,548,interpolation=\"bilinear\")\n",
        "\n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "      #input_layer = tf.keras.Input(shape = [412, 548, 3])(input_tensor)\n",
        "     \n",
        "      input_tensor=self.input_layer(input_tensor)\n",
        "      \n",
        "      conv1 = self.conv1(input_tensor)\n",
        "      conv1 = self.conv1_1(conv1)\n",
        "      pool1 = self.pool1(conv1)\n",
        "      pool1 = self.pool1_1(pool1,training=training)\n",
        "      \n",
        "      conv2 = self.conv2(pool1)\n",
        "      conv2 = self.conv2_2(conv2)\n",
        "      pool2 = self.pool2(conv2)\n",
        "      pool2 = self.pool2_2(pool2,training=training)\n",
        "\n",
        "      conv3 = self.conv3(pool2)\n",
        "      conv3 = self.conv3_3(conv3)\n",
        "      pool3 = self.pool3(conv3)\n",
        "      pool3 = self.pool3_3(pool3,training=training)\n",
        "\n",
        "      conv4 = self.conv4(pool3)\n",
        "      conv4 = self.conv4_4(conv4)\n",
        "      pool4 = self.pool4(conv4)\n",
        "      pool4 = self.pool4_4(pool4,training=training)\n",
        "     \n",
        "      \n",
        "      # Middle\n",
        "      convm =self.convm(pool4)\n",
        "      convm =self.convm_1(convm)\n",
        "      \n",
        "      \n",
        "      deconv4 =self.deconv4(convm)\n",
        "      \n",
        "      uconv4 = concatenate([deconv4, conv4])\n",
        "      \n",
        "      uconv4 = self.uconv4_1(uconv4,training=training)\n",
        "      uconv4 = self.uconv4_2(uconv4)\n",
        "      uconv4 = self.uconv4_3(uconv4)\n",
        "\n",
        "      deconv3 =self.deconv3(uconv4)\n",
        "      uconv3 = concatenate([deconv3, conv3])\n",
        "      uconv3 = self.uconv3_1(uconv3,training=training)\n",
        "      uconv3 = self.uconv3_2(uconv3)\n",
        "      uconv3 = self.uconv3_3(uconv3)\n",
        "\n",
        "      deconv2 =self.deconv2(uconv3)\n",
        "      uconv2= concatenate([deconv2, conv2])\n",
        "      uconv2 = self.uconv2_1(uconv2,training=training)\n",
        "      uconv2 = self.uconv2_2(uconv2)\n",
        "      uconv2 = self.uconv2_3(uconv2)\n",
        "\n",
        "      deconv1 =self.deconv1(uconv2)\n",
        "      uconv1 = concatenate([deconv1, conv1])\n",
        "      uconv1 = self.uconv1_1(uconv1,training=training)\n",
        "      uconv1 = self.uconv1_2(uconv1)\n",
        "      uconv1 = self.uconv1_3(uconv1)\n",
        "      \n",
        "\n",
        "      \n",
        "      \n",
        "      output_layer = self.output_layer(uconv1)\n",
        "      output_layer=self.output_(output_layer)\n",
        "\n",
        "      return output_layer\n",
        "\n",
        "    def model(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "    def build_graph(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs9uyu-sRAH3"
      },
      "source": [
        "k_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      \n",
        "regularizer = tf.keras.regularizers.L2(1e-4)\n",
        "b_init = tf.constant_initializer()\n",
        "\n",
        "\n",
        "def gman_net():\n",
        "    \n",
        "    inputs = tf.keras.Input(shape = [412, 548, 6])     # height, width of input image changed because of error in output\n",
        "    #i=tf.image.resize(inputs, size = (412, 548), antialias = True)\n",
        "    inputs = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(inputs)\n",
        "                                    ######################## GMAN Network ###########################\n",
        "    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'valid', kernel_initializer = k_init, activation = 'relu',\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(inputs)  \n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
        "    \n",
        "    \n",
        "                                    #### Encoding Layers #####\n",
        "    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
        "    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)\n",
        "                                    \n",
        "                                    #### Residual Layers #####\n",
        "    conv1_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)\n",
        "    conv1_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_1)\n",
        "    conv1_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_2)\n",
        "    conc1 = tf.add(conv1_3, conv1_1)\n",
        "    conv1 = tf.keras.activations.relu(conc1)\n",
        "\n",
        "    conv2_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1)\n",
        "    conv2_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_1)\n",
        "    conv2_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_2)\n",
        "    conc2 = tf.add(conv2_3, conv2_1)\n",
        "    conv2 = tf.keras.activations.relu(conc2)\n",
        "\n",
        "    conv3_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2)\n",
        "    conv3_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_1)\n",
        "    conv3_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_2)\n",
        "    conv3_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_3)\n",
        "    conv3_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_4)\n",
        "    conc3 = tf.add(conv3_5, conv3_1)\n",
        "    conv3 = tf.keras.activations.relu(conc3)\n",
        "\n",
        "    conv4_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3)\n",
        "    conv4_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_1)\n",
        "    conv4_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_2)\n",
        "    conv4_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_3)\n",
        "    conv4_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_4)\n",
        "    conc4 = tf.add(conv4_5, conv4_1)\n",
        "    conv4 = tf.keras.activations.relu(conc4)\n",
        "\n",
        "                                            ##### Decoding Layers #####\n",
        "    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                             kernel_regularizer = regularizer)(conv4)\n",
        "    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                             kernel_regularizer = regularizer)(deconv)\n",
        "\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(deconv)\n",
        "    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
        "    conc = tf.add(conv, inputs)\n",
        "    gman_output = tf.keras.activations.relu(conc)\n",
        "    \n",
        "                               ######################## Parallel Network ###########################\n",
        "    \n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(inputs)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(conv)\n",
        "    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                           activation = 'relu', kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                 kernel_regularizer = regularizer)(deconv)\n",
        "    conc = tf.add(conv, inputs)\n",
        "    pn_output = tf.keras.activations.relu(conc)\n",
        "    \n",
        "    output = tf.add(gman_output, pn_output)\n",
        "    \n",
        "    return Model(inputs = inputs, outputs = output)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PINEUpA5LOqX"
      },
      "source": [
        "class custom_Loss(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "      super(custom_Loss, self).__init__()\n",
        "      self.unet=unet()\n",
        "      self.dehazenet=dehazenet_attention()\n",
        "      #self.gman=gman_net()\n",
        "      self.conv=Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu')\n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "     #x=self.unet(input_tensor,training=training)\n",
        "     x=self.dehazenet(input_tensor,training=training)\n",
        "     #y=self.dehazenet(input_tensor,training=training)\n",
        "     #x= concatenate([x,y])\n",
        "     #x=self.conv(x)\n",
        "     x1=self.dehazenet(x)\n",
        "     '''\n",
        "     x=self.unet(x,training=training)\n",
        "     y=self.dehazenet(x,training=training)\n",
        "     x= concatenate([x,y])\n",
        "\n",
        "     x=self.unet(x,training=training)\n",
        "     y=self.dehazenet(x,training=training)\n",
        "     x= concatenate([x,y])\n",
        "\n",
        "     x=self.unet(x,training=training)\n",
        "     y=self.dehazenet(x,training=training)\n",
        "     x= concatenate([x,y])\n",
        "     '''\n",
        "     return x1\n",
        "\n",
        "  def model(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "  def build_graph(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNT0WSxTLL40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "1eab9201-8c1a-4a4d-9fca-c5b0e5604980"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "model= custom_Loss()\n",
        "model.model().summary()\n",
        "\n",
        "dot_img_file = '/tmp/model_1.png'\n",
        "tf.keras.utils.plot_model(\n",
        "    model.build_graph(),                      # here is the trick (for now)\n",
        "    to_file='model.png', dpi=96,              # saving  \n",
        "    show_shapes=True, show_layer_names=True,  # show shapes and layer name\n",
        "    expand_nested=False                       # will show nested block\n",
        ")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 412, 548, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dehazenet_attention_10 (dehazen (None, 412, 548, 3)  6421        input_11[0][0]                   \n",
            "                                                                 dehazenet_attention_10[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 6,421\n",
            "Trainable params: 6,421\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I3VLf5aHwNB"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND43J41TLSzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67221a9c-d7b5-483e-8285-33e69ac732f2"
      },
      "source": [
        "# Hyperparameters\n",
        "import random\n",
        "epochs = 8\n",
        "batch_size = 1\n",
        "\n",
        "\n",
        "#train_data, val_data = data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze')\n",
        "train_data, val_data = data_path(orig_img_path = './drive/MyDrive/dataset/clear_images', hazy_img_path = './drive/MyDrive/dataset/haze')\n",
        "train, val = dataloader(train_data, val_data, batch_size)\n",
        "\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "net = custom_Loss()\n",
        "#net= tf.keras.models.load_model('/content/drive/MyDrive/nets/test_custom_loss_net',compile=False)\n",
        "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\n",
        "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqftUl4eGtp7"
      },
      "source": [
        "a=[];b=[]\n",
        "class MyLoss_layer(tf.keras.losses.Loss):\n",
        "    def __init__(self, from_logits=False,reduction=tf.keras.losses.Reduction.NONE,name='MyLoss_layer'):#=tf.keras.losses.Reduction.AUTO,\n",
        "        super(MyLoss_layer, self).__init__(reduction=reduction, name=name)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        custom_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "        custom_Loss+=1\n",
        "        return custom_loss\n",
        "\n",
        "\n",
        "\n",
        "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
        "    #global a\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
        "        start_time_epoch = time.time()\n",
        "        start_time_step = time.time()\n",
        "        \n",
        "        # training loop\n",
        "        \n",
        "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
        "            #global a\n",
        "            #a=train_batch_haze\n",
        "            #global b\n",
        "            #b=train_batch_orig\n",
        "            #print(type(train_batch_haze))\n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "                train_logits = net(train_batch_haze, training = True)\n",
        "                loss = mean_squared_error(train_batch_orig, train_logits)\n",
        "                #loss = MyLoss_layer(train_batch_orig, train_logits)\n",
        "\n",
        "\n",
        "            grads = tape.gradient(loss, net.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
        "\n",
        "            train_loss_tracker.update_state(train_batch_orig, train_logits)\n",
        "            if step == 0:\n",
        "                print('[', end='')\n",
        "            if step % 64 == 0:\n",
        "                print('=', end='')\n",
        "        \n",
        "        print(']', end='')\n",
        "        print('  -  ', end='')\n",
        "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
        "        \n",
        "        # validation loop\n",
        "        \n",
        "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
        "            val_logits = net(val_batch_haze, training = False)\n",
        "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
        "            \n",
        "            if step % 32 ==0:\n",
        "                display_img(net, val_batch_haze, val_batch_orig)\n",
        "        \n",
        "        print('  -  ', end='')\n",
        "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
        "        print('  -  ', end=' ')\n",
        "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
        "        \n",
        "        net.save('trained_model')           # save the model(variables, weights, etc)\n",
        "        train_loss_tracker.reset_states()\n",
        "        val_loss_tracker.reset_states()\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxobCF_TGvMW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "63fbc76f-e75a-4bff-8730-3d1156b57c4b"
      },
      "source": [
        "\n",
        "\n",
        "%%time\n",
        "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-2b67466aa0be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-47f18cbe41fa>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mtrain_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_haze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;31m#loss = MyLoss_layer(train_batch_orig, train_logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-d9b54732221b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tensor, training)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m      \u001b[0;31m#x=self.unet(input_tensor,training=training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m      \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdehazenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m      \u001b[0;31m#y=self.dehazenet(input_tensor,training=training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m      \u001b[0;31m#x= concatenate([x,y])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-069da1403d7e>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_tensor, training)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mChanAtLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m       \u001b[0mx1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m       \u001b[0mx2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0mconcat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1018\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1148\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2602\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2604\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2605\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2606\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    930\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Conv2D: Dst tensor is not initialized. [Op:Conv2D]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmY_-owraQvu"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6DS2JJKG1nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e7ae05-8ba0-484d-93af-db87ce62cbad"
      },
      "source": [
        "net.save('./drive/MyDrive/nets/test_custom_loss_net')\n",
        "model=net\n",
        "#model.build([412,548,3])\n",
        "#model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/nets/test_custom_loss_net/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/nets/test_custom_loss_net/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XxulTP8G6vZ"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def msee(imageA, imageB):\n",
        "\t# the 'Mean Squared Error' between the two images is the\n",
        "\t# sum of the squared difference between the two images;\n",
        "\t# NOTE: the two images must have the same dimension\n",
        "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
        "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
        "\t\n",
        "\t# return the MSE, the lower the error, the more \"similar\"\n",
        "\t# the two images are\n",
        "\treturn err\n",
        "def compare_images(imageA, imageB):\n",
        "  # compute the mean squared error and structural similarity\n",
        "  # index for the images\n",
        "  m = msee(imageA, imageB)\n",
        "  s = ssim(imageA, imageB,multichannel=True)\n",
        "  return s\n",
        "  #s=tf.image.ssim(imageA, imageB, max_val=255, filter_size=11,filter_sigma=1.5, k1=0.01, k2=0.03)\n",
        "def find_psnr(imageA,imageB):\n",
        "   return cv2.PSNR(imageA,imageB)\n",
        "\n",
        "def evaluate_gen(net):\n",
        "    \n",
        "    #test_img = glob.glob(test_img_path +'/*.jpg')\n",
        "    test_img=glob.glob('/content/drive/MyDrive/Final_compare/HAZY/*.jpg')\n",
        "    \n",
        "    #random.shuffle(test_img)\n",
        "    i=1;\n",
        "    for img in test_img:\n",
        "        \n",
        "        img = tf.io.read_file(img)\n",
        "        img = tf.io.decode_jpeg(img, channels = 3)\n",
        "        \n",
        "        img = tf.image.resize(img, size = (412,548), antialias = True)\n",
        "        \n",
        "        img = img / 255.0\n",
        "        print(i,end=\" \")\n",
        "        img = tf.expand_dims(img, axis = 0)      #transform input image from 3D to 4D ###\n",
        "        \n",
        "        dehaze = net(img)\n",
        "        dehaze=tf.image.resize(dehaze, size = (413,550), antialias = True)\n",
        "        #plt.figure(figsize = (80, 80))\n",
        "        \n",
        "        #display_list = [img[0], dehaze[0]]       #make the first dimension zero\n",
        "        im=dehaze[0]\n",
        "        directory = '/content/drive/MyDrive/Final_compare/test_custom_loss_net'\n",
        "        \n",
        "        os.chdir(directory)\n",
        "        filename = str(i) + '_outdoor_gen.jpg'\n",
        "        #print(filename)\n",
        "        #cv2.imwrite(filename,im) \n",
        "        #plt.imsave(filename,im)\n",
        "        tf.keras.preprocessing.image.save_img(filename,im)\n",
        "\n",
        "        os.chdir('/content')\n",
        "        i+=1;\n",
        "    orig_img_path='/content/drive/MyDrive/Final_compare/GT'\n",
        "    orig_img = glob.glob(orig_img_path + '/*.jpg')\n",
        "    orig_img.sort()\n",
        "\n",
        "    test_img_path='/content/drive/MyDrive/Final_compare/test_custom_loss_net'\n",
        "    \n",
        "    test_img = glob.glob(test_img_path + '/*.jpg')\n",
        "    test_img.sort()\n",
        "\n",
        "\n",
        "    psnr_val=0;ssim_val=0;\n",
        "    n=len(orig_img)\n",
        "    for i in range(len(orig_img)):\n",
        "      os.chdir(orig_img_path)\n",
        "      original = cv2.imread(orig_img[i]) \n",
        "      #original=tf.image.resize_with_crop_or_pad(original, 400, 520)\n",
        "      original = original[3:-4,3:-4,]\n",
        "      os.chdir(test_img_path)\n",
        "      hazy = cv2.imread(test_img[i]) \n",
        "      #hazy=tf.image.resize_with_crop_or_pad(hazy, 400, 520)\n",
        "      hazy=hazy[3:-4,3:-4]\n",
        "      psnr_val+=find_psnr(original, hazy)\n",
        "      ssim_val+=compare_images(original, hazy)\n",
        "      #print(i,end=\" \")\n",
        "    total_psnr=psnr_val/n\n",
        "    total_ssim=ssim_val/n\n",
        "    print(\"\\n psnr=\",total_psnr)\n",
        "    print(\"ssim=\",total_ssim)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDIcNhLTHIQP"
      },
      "source": [
        "\n",
        "\n",
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/test_custom_loss_net',compile=False)\n",
        "\n",
        "\n",
        "evaluate_gen(new_model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP10YhKaHVB9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}