{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "gman-net-for-image-dehazing.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "scrolled": false,
        "id": "N39U696_KnKD"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NetxtfKRKv7K",
        "outputId": "f0355d2d-0881-4b13-b9c1-993cbedb638d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FE6nygwKnKd"
      },
      "source": [
        "# Preprocessing and loading of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQvDpNGaB_l"
      },
      "source": [
        "#ls drive/MyDrive/reside/archive/clear_images drive/MyDrive/reside/archive/haze  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "uk0gyj-8KnKe"
      },
      "source": [
        "# function to load the image in the form of tensors.\n",
        "\n",
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (412, 548), antialias = True)\n",
        "    img = img / 255.0\n",
        "    return img"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "vvpitygGKnKf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9bd11a76-2874-432d-87b8-143da7fd0bea"
      },
      "source": [
        "# function to get the path of individual image.\n",
        "'''\n",
        "def data_path(orig_img_path, hazy_img_path):\n",
        "    \n",
        "    train_img = []\n",
        "    val_img = []\n",
        "    \n",
        "    orig_img = glob.glob(orig_img_path + '/*.jpg')\n",
        "    n = len(orig_img)\n",
        "    random.shuffle(orig_img)\n",
        "    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\n",
        "    val_keys = orig_img[int(0.9*n):]\n",
        "    \n",
        "    split_dict = {}\n",
        "    for key in train_keys:\n",
        "        split_dict[key] = 'train'\n",
        "    for key in val_keys:\n",
        "        split_dict[key] = 'val'\n",
        "        \n",
        "    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\n",
        "    for img in hazy_img:\n",
        "        img_name = img.split('/')[-1]\n",
        "        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'\n",
        "        if (split_dict[orig_path] == 'train'):\n",
        "            train_img.append([img, orig_path])\n",
        "        else:\n",
        "            val_img.append([img, orig_path])\n",
        "            \n",
        "    return train_img, val_img\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndef data_path(orig_img_path, hazy_img_path):\\n    \\n    train_img = []\\n    val_img = []\\n    \\n    orig_img = glob.glob(orig_img_path + '/*.jpg')\\n    n = len(orig_img)\\n    random.shuffle(orig_img)\\n    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\\n    val_keys = orig_img[int(0.9*n):]\\n    \\n    split_dict = {}\\n    for key in train_keys:\\n        split_dict[key] = 'train'\\n    for key in val_keys:\\n        split_dict[key] = 'val'\\n        \\n    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\\n    for img in hazy_img:\\n        img_name = img.split('/')[-1]\\n        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'\\n        if (split_dict[orig_path] == 'train'):\\n            train_img.append([img, orig_path])\\n        else:\\n            val_img.append([img, orig_path])\\n            \\n    return train_img, val_img\\n    \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_AfOmlD7n8X"
      },
      "source": [
        "def dataset_preposses(orig_path='/content/drive/MyDrive/dataset/clear_images',haze_path='/content/drive/MyDrive/dataset/haze',percentage=0.3,validation_size=64,test_size=64,seed_val=101):\n",
        "  '''\n",
        "  parameters:\n",
        "  orig_path(string): path of ground truth folder\n",
        "  haze_path(string): path of haze folder\n",
        "  percentage(float): percentage of dataset to load\n",
        "  validation_size(int): the no. of validation images\n",
        "  test_size(int): the no. of test images\n",
        "\n",
        "  returns:\n",
        "  haze_list,validation_list,test_list\n",
        "  '''\n",
        "  random.seed(seed_val)\n",
        "  pth=haze_path+'/*.jpg'\n",
        "  haze_path_list = glob.glob(pth)\n",
        "  orig_path_list=glob.glob(orig_path+'/*.jpg')\n",
        "  #print(orig_path_list)\n",
        "  random.shuffle(haze_path_list)\n",
        "  #print(haze_path_list)\n",
        "  haze_path_dict={}\n",
        "  haze_count_dict={}\n",
        "  haze_list=[]\n",
        "  no_per_set=int(percentage*35)\n",
        "  for i in haze_path_list:\n",
        "    name=i.split('/')[-1].split('_')[0]\n",
        "    if(int(name)>468):\n",
        "      try:\n",
        "        if(haze_count_dict[name]<no_per_set):\n",
        "          haze_path_dict[name].append(i)\n",
        "          \n",
        "          haze_count_dict[name]+=1;\n",
        "          \n",
        "      except KeyError:\n",
        "       \n",
        "        haze_path_dict[name]=[]\n",
        "        haze_path_dict[name].append(i)\n",
        "        haze_count_dict[name]=1\n",
        "    #print(haze_path_dict)\n",
        "  test_list=haze_path_list[-1*test_size:]\n",
        "  val_list=haze_path_list[-1*(validation_size+test_size):-1*test_size];\n",
        "\n",
        "  for (key,val) in haze_path_dict.items():\n",
        "    for i in val:\n",
        "      haze_list.append(i)\n",
        "  return haze_list,val_list,test_list\n",
        "\n",
        "\n",
        "def gen_dataset(ar):\n",
        "  '''\n",
        "  parameters\n",
        "  list of paths\n",
        "  return\n",
        "  list with gt attached \n",
        "  '''\n",
        "  orig_path='/content/drive/MyDrive/dataset/clear_images'\n",
        "  haze_pth='/content/drive/MyDrive/dataset/haze'\n",
        "  lst=[]\n",
        "  for i in ar:\n",
        "    name=i.split('/')[-1].split('_')[0]\n",
        "    pthlist=[i,orig_path+'/'+name+'.jpg']\n",
        "    lst.append(pthlist)\n",
        "  return lst\n",
        "\n",
        "def data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze'):\n",
        "  \n",
        "  (a,b,c)=dataset_preposses(orig_path=orig_img_path,haze_path=hazy_img_path)\n",
        "  a=gen_dataset(a)\n",
        "  b=gen_dataset(b)\n",
        "  return a,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "D-194d5sKnKg"
      },
      "source": [
        "# function to load tensor image data in batches.\n",
        "\n",
        "def dataloader(train_data, val_data, batch_size):\n",
        "    \n",
        "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    return train, val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "2aU_zzDHKnKh"
      },
      "source": [
        "# function to display output.\n",
        "\n",
        "def display_img(model, hazy_img, orig_img):\n",
        "    \n",
        "    dehazed_img = model(hazy_img, training = True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    \n",
        "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
        "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuypKuZZKnKi"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_kg_hide-input": true,
        "id": "WRCns3vCKnKi"
      },
      "source": [
        "def gman_net():\n",
        "    \n",
        "    inputs = tf.keras.Input(shape = [412, 548, 3])     # height, width of input image changed because of error in output\n",
        "    #i=tf.image.resize(inputs, size = (412, 548), antialias = True)\n",
        "                                    ######################## GMAN Network ###########################\n",
        "    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'valid', kernel_initializer = k_init, activation = 'relu',\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(inputs)  \n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
        "    \n",
        "    \n",
        "                                    #### Encoding Layers #####\n",
        "    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
        "    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)\n",
        "                                    \n",
        "                                    #### Residual Layers #####\n",
        "    conv1_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)\n",
        "    conv1_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_1)\n",
        "    conv1_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_2)\n",
        "    conc1 = tf.add(conv1_3, conv1_1)\n",
        "    conv1 = tf.keras.activations.relu(conc1)\n",
        "\n",
        "    conv2_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1)\n",
        "    conv2_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_1)\n",
        "    conv2_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_2)\n",
        "    conc2 = tf.add(conv2_3, conv2_1)\n",
        "    conv2 = tf.keras.activations.relu(conc2)\n",
        "\n",
        "    conv3_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2)\n",
        "    conv3_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_1)\n",
        "    conv3_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_2)\n",
        "    conv3_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_3)\n",
        "    conv3_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_4)\n",
        "    conc3 = tf.add(conv3_5, conv3_1)\n",
        "    conv3 = tf.keras.activations.relu(conc3)\n",
        "\n",
        "    conv4_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3)\n",
        "    conv4_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_1)\n",
        "    conv4_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_2)\n",
        "    conv4_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_3)\n",
        "    conv4_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_4)\n",
        "    conc4 = tf.add(conv4_5, conv4_1)\n",
        "    conv4 = tf.keras.activations.relu(conc4)\n",
        "\n",
        "                                            ##### Decoding Layers #####\n",
        "    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                             kernel_regularizer = regularizer)(conv4)\n",
        "    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                             kernel_regularizer = regularizer)(deconv)\n",
        "\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(deconv)\n",
        "    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
        "    conc = tf.add(conv, inputs)\n",
        "    gman_output = tf.keras.activations.relu(conc)\n",
        "    \n",
        "                               ######################## Parallel Network ###########################\n",
        "    \n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(inputs)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
        "                 kernel_regularizer = regularizer)(conv)\n",
        "    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                           activation = 'relu', kernel_regularizer = regularizer)(conv)\n",
        "    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
        "                 kernel_regularizer = regularizer)(deconv)\n",
        "    conc = tf.add(conv, inputs)\n",
        "    pn_output = tf.keras.activations.relu(conc)\n",
        "    \n",
        "    output = tf.add(gman_output, pn_output)\n",
        "    \n",
        "    return Model(inputs = inputs, outputs = output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3_vsnPJ8Vlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464741ae-0133-422e-dabb-bcde8e287d4b"
      },
      "source": [
        "model=gman_net()\n",
        "model.build([413,550,3])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 412, 548, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 410, 546, 3)  84          input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 410, 546, 64) 1792        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 410, 546, 64) 36928       conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 205, 273, 128 73856       conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 103, 137, 128 147584      conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 103, 137, 64) 73792       conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.add_27 (TFOpLambda)     (None, 103, 137, 64) 0           conv2d_127[0][0]                 \n",
            "                                                                 conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_22 (TFOpLambda)      (None, 103, 137, 64) 0           tf.math.add_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 103, 137, 64) 36928       tf.nn.relu_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.add_28 (TFOpLambda)     (None, 103, 137, 64) 0           conv2d_130[0][0]                 \n",
            "                                                                 conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_23 (TFOpLambda)      (None, 103, 137, 64) 0           tf.math.add_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 103, 137, 64) 36928       tf.nn.relu_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.add_29 (TFOpLambda)     (None, 103, 137, 64) 0           conv2d_135[0][0]                 \n",
            "                                                                 conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_24 (TFOpLambda)      (None, 103, 137, 64) 0           tf.math.add_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 103, 137, 64) 36928       tf.nn.relu_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 412, 548, 64) 1792        input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 103, 137, 64) 36928       conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 412, 548, 64) 36928       conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.add_30 (TFOpLambda)     (None, 103, 137, 64) 0           conv2d_140[0][0]                 \n",
            "                                                                 conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 412, 548, 64) 36928       conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_25 (TFOpLambda)      (None, 103, 137, 64) 0           tf.math.add_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 412, 548, 64) 36928       conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DTran (None, 206, 274, 64) 36928       tf.nn.relu_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 412, 548, 64) 36928       conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DTran (None, 412, 548, 64) 36928       conv2d_transpose_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 412, 548, 64) 36928       conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 412, 548, 64) 36928       conv2d_transpose_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_13 (Conv2DTran (None, 412, 548, 64) 36928       conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 412, 548, 3)  1731        conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 412, 548, 3)  1731        conv2d_transpose_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.add_31 (TFOpLambda)     (None, 412, 548, 3)  0           conv2d_142[0][0]                 \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.add_32 (TFOpLambda)     (None, 412, 548, 3)  0           conv2d_149[0][0]                 \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_26 (TFOpLambda)      (None, 412, 548, 3)  0           tf.math.add_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_27 (TFOpLambda)      (None, 412, 548, 3)  0           tf.math.add_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.add_33 (TFOpLambda)     (None, 412, 548, 3)  0           tf.nn.relu_26[0][0]              \n",
            "                                                                 tf.nn.relu_27[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,225,562\n",
            "Trainable params: 1,225,562\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "HhB7n03AKnKo"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs =5\n",
        "batch_size = 8\n",
        "k_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      \n",
        "regularizer = tf.keras.regularizers.L2(1e-4)\n",
        "b_init = tf.constant_initializer()\n",
        "\n",
        "#train_data, val_data = data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze')\n",
        "train_data, val_data = data_path(orig_img_path = '/content/drive/MyDrive/dataset/clear_images', hazy_img_path = '/content/drive/MyDrive/dataset/haze')\n",
        "train, val = dataloader(train_data, val_data, batch_size)\n",
        "\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "#net = gman_net()\n",
        "net= tf.keras.models.load_model('/content/drive/MyDrive/nets/gman',compile=False)\n",
        "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\n",
        "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_kg_hide-output": true,
        "id": "L7pz9bV9KnKr"
      },
      "source": [
        "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
        "        start_time_epoch = time.time()\n",
        "        start_time_step = time.time()\n",
        "        \n",
        "        # training loop\n",
        "        \n",
        "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "                train_logits = net(train_batch_haze, training = True)\n",
        "                loss = mean_squared_error(train_batch_orig, train_logits)\n",
        "\n",
        "            grads = tape.gradient(loss, net.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
        "\n",
        "            train_loss_tracker.update_state(train_batch_orig, train_logits)\n",
        "            if step == 0:\n",
        "                print('[', end='')\n",
        "            if step % 64 == 0:\n",
        "                print('=', end='')\n",
        "        \n",
        "        print(']', end='')\n",
        "        print('  -  ', end='')\n",
        "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
        "        \n",
        "        # validation loop\n",
        "        \n",
        "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
        "            val_logits = net(val_batch_haze, training = False)\n",
        "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
        "            \n",
        "            if step % 32 ==0:\n",
        "                display_img(net, val_batch_haze, val_batch_orig)\n",
        "        \n",
        "        print('  -  ', end='')\n",
        "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
        "        print('  -  ', end=' ')\n",
        "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
        "        \n",
        "        net.save('trained_model')           # save the model(variables, weights, etc)\n",
        "        train_loss_tracker.reset_states()\n",
        "        val_loss_tracker.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "sbnB0QNYKnKs",
        "outputId": "25bf3b96-11f6-446c-e0ef-035d20d29482"
      },
      "source": [
        "%%time\n",
        "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0 [====="
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-b0302f0e0cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-0935632fb9e2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_haze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_orig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2574\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2575\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2577\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wu9xhQ-0kcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454488f1-7f7f-4745-c848-1eeca3fbfd2a"
      },
      "source": [
        "net.save('./drive/MyDrive/nets/gman')\n",
        "model=net\n",
        "#model.build([412,548,3])\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/nets/gman/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "id": "hj2jEwFxKnKt"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_gen(net):\n",
        "    \n",
        "    #test_img = glob.glob(test_img_path +'/*.jpg')\n",
        "    test_img=glob.glob('/content/drive/MyDrive/Final_compare/HAZY/*.jpg')\n",
        "    #test_img=glob.glob('/content/drive/MyDrive/Final_compare/gman/*.jpg')\n",
        "    #random.shuffle(test_img)\n",
        "    i=1;\n",
        "    for img in test_img:\n",
        "        \n",
        "        img = tf.io.read_file(img)\n",
        "        img = tf.io.decode_jpeg(img, channels = 3)\n",
        "        \n",
        "        img = tf.image.resize(img, size = (412,548), antialias = True)\n",
        "        \n",
        "        img = img / 255.0\n",
        "        print(i,end=\" \")\n",
        "        img = tf.expand_dims(img, axis = 0)      #transform input image from 3D to 4D ###\n",
        "        \n",
        "        dehaze = net(img)\n",
        "        dehaze=tf.image.resize(dehaze, size = (413,550), antialias = True)\n",
        "        #plt.figure(figsize = (80, 80))\n",
        "        \n",
        "        #display_list = [img[0], dehaze[0]]       #make the first dimension zero\n",
        "        im=dehaze[0]\n",
        "        #directory = '/content/drive/MyDrive/Final_compare/gman'\n",
        "        directory = '/content/drive/MyDrive/Final_compare/LoopCompare'\n",
        "        os.chdir(directory)\n",
        "        filename = str(i) + '_outdoor_gen.jpg'\n",
        "        #print(filename)\n",
        "        #cv2.imwrite(filename,im) \n",
        "        #plt.imsave(filename,im)\n",
        "        tf.keras.preprocessing.image.save_img(\n",
        "    filename, \n",
        "\n",
        "im)\n",
        "\n",
        "        os.chdir('/content')\n",
        "        i+=1;\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_kg_hide-output": true,
        "id": "UUCDXhKnKnKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15573f33-8bf2-4e66-d4e5-5c9b42c41195"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/gman',compile=False)\n",
        "#new_model = tf.keras.models.load_model('/content/drive/MyDrive/nets/gman/trained_model',compile=False)\n",
        "\n",
        "evaluate_gen(new_model)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMg7MNzdkWCH"
      },
      "source": [
        "\n",
        "\n",
        "cp -r trained_model/ /content/drive/MyDrive/nets/dehazenet/trained_model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZJmVhXGkno_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}