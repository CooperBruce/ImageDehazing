{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "\n",
    "def load_image(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.io.decode_jpeg(img, channels = 3)      # Decode a JPEG-encoded image to a uint8 tensor.\n",
    "    img = tf.image.resize(img, size = (412, 548), antialias = True)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def data_path(orig_img_path, hazy_img_path):\n",
    "\n",
    "    train_img = []\n",
    "    val_img = []\n",
    "\n",
    "    orig_img = glob.glob(orig_img_path + '/*.png')\n",
    "    n = len(orig_img)\n",
    "    random.shuffle(orig_img)\n",
    "    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\n",
    "    val_keys = orig_img[int(0.9*n):]\n",
    "\n",
    "    split_dict = {}\n",
    "    for key in train_keys:\n",
    "        split_dict[key] = 'train'\n",
    "    for key in val_keys:\n",
    "        split_dict[key] = 'val'\n",
    "\n",
    "    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\n",
    "    for img in hazy_img:\n",
    "        img_name = img.split('/')[-1]\n",
    "        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.png'\n",
    "        if (split_dict[orig_path] == 'train'):\n",
    "            train_img.append([img, orig_path])\n",
    "        else:\n",
    "            val_img.append([img, orig_path])\n",
    "\n",
    "    return train_img, val_img\n",
    "\n",
    "def dataloader(train_data, val_data, batch_size):\n",
    "\n",
    "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
    "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
    "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
    "\n",
    "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
    "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
    "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
    "\n",
    "    return train, val\n",
    "\n",
    "def display_img(model, hazy_img, orig_img):\n",
    "\n",
    "    dehazed_img = model(hazy_img, training = True)\n",
    "    plt.figure(figsize = (15,15))\n",
    "\n",
    "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
    "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls /home/abu/Downloads/archive/clear_images /home/abu/Downloads/archive/haze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_lst,val_lst=data_path('../../../','../../../../SOTS/outdoor/hazy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1cb0d69914cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_lst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_lst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_lst' is not defined"
     ]
    }
   ],
   "source": [
    "train_img,val_img=dataloader(train_lst,val_lst,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gman_net():\n",
    "    \n",
    "    inputs = tf.keras.Input(shape = [412, 548, 3])     # height, width of input image changed because of error in output\n",
    "    \n",
    "                                    ######################## GMAN Network ###########################\n",
    "        \n",
    "    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                  bias_initializer = b_init, kernel_regularizer = regularizer)(inputs)\n",
    "    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
    "    \n",
    "    \n",
    "                                    #### Encoding Layers #####\n",
    "    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
    "    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)\n",
    "                                    \n",
    "                                    #### Residual Layers #####\n",
    "    conv1_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)\n",
    "    conv1_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_1)\n",
    "    conv1_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
    "                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_2)\n",
    "    conc1 = tf.add(conv1_3, conv1_1)\n",
    "    conv1 = tf.keras.activations.relu(conc1)\n",
    "\n",
    "    conv2_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1)\n",
    "    conv2_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_1)\n",
    "    conv2_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_2)\n",
    "    conc2 = tf.add(conv2_3, conv2_1)\n",
    "    conv2 = tf.keras.activations.relu(conc2)\n",
    "\n",
    "    conv3_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2)\n",
    "    conv3_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_1)\n",
    "    conv3_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_2)\n",
    "    conv3_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_3)\n",
    "    conv3_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_4)\n",
    "    conc3 = tf.add(conv3_5, conv3_1)\n",
    "    conv3 = tf.keras.activations.relu(conc3)\n",
    "\n",
    "    conv4_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3)\n",
    "    conv4_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_1)\n",
    "    conv4_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_2)\n",
    "    conv4_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_3)\n",
    "    conv4_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
    "                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_4)\n",
    "    conc4 = tf.add(conv4_5, conv4_1)\n",
    "    conv4 = tf.keras.activations.relu(conc4)\n",
    "\n",
    "                                            ##### Decoding Layers #####\n",
    "    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
    "                             kernel_regularizer = regularizer)(conv4)\n",
    "    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
    "                             kernel_regularizer = regularizer)(deconv)\n",
    "\n",
    "    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                  bias_initializer = b_init, kernel_regularizer = regularizer)(deconv)\n",
    "    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
    "                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)\n",
    "    conc = tf.add(conv, inputs)\n",
    "    gman_output = tf.keras.activations.relu(conc)\n",
    "    \n",
    "                               ######################## Parallel Network ###########################\n",
    "    \n",
    "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                 kernel_regularizer = regularizer)(inputs)\n",
    "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                 kernel_regularizer = regularizer)(conv)\n",
    "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                 kernel_regularizer = regularizer)(conv)\n",
    "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                 kernel_regularizer = regularizer)(conv)\n",
    "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                 kernel_regularizer = regularizer)(conv)\n",
    "    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',\n",
    "                 kernel_regularizer = regularizer)(conv)\n",
    "    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
    "                           activation = 'relu', kernel_regularizer = regularizer)(conv)\n",
    "    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),\n",
    "                 kernel_regularizer = regularizer)(deconv)\n",
    "    conc = tf.add(conv, inputs)\n",
    "    pn_output = tf.keras.activations.relu(conc)\n",
    "    \n",
    "    output = tf.add(gman_output, pn_output)\n",
    "    \n",
    "    return Model(inputs = inputs, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
    "        start_time_epoch = time.time()\n",
    "        start_time_step = time.time()\n",
    "        \n",
    "        # training loop\n",
    "        \n",
    "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
    "\n",
    "            with tf.GradientTape() as tape:        # Record operations for automatic differentiation.\n",
    "\n",
    "                train_logits = net(train_batch_haze, training = True)   # Give training data as input.\n",
    "                loss = mean_squared_error(train_batch_orig, train_logits)   # Calculate the loss between original image and output of training \n",
    "\n",
    "            grads = tape.gradient(loss, net.trainable_weights)   # Compute multiple gradients over the same computation.\n",
    "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
    "\n",
    "            train_loss_tracker.update_state(train_batch_orig, train_logits)    # Update the loss after every epoch\n",
    "            if step == 0:\n",
    "                print('[', end='')\n",
    "            if step % 64 == 0:\n",
    "                print('=', end='')\n",
    "        \n",
    "        print(']', end='')\n",
    "        print('  -  ', end='')\n",
    "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
    "        \n",
    "        # validation loop\n",
    "        \n",
    "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
    "            val_logits = net(val_batch_haze, training = False)\n",
    "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
    "            \n",
    "            if step % 32 ==0:\n",
    "                display_img(net, val_batch_haze, val_batch_orig)\n",
    "        \n",
    "        print('  -  ', end='')\n",
    "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
    "        print('  -  ', end=' ')\n",
    "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
    "        \n",
    "        net.save('trained_model')           # save the model(variables, weights, etc).\n",
    "        train_loss_tracker.reset_states()     # Reset the loss for new loss from next epoch.\n",
    "        val_loss_tracker.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'/home/abu/Downloads/archive/clear_images/0562.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-48965caf4d93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mb_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m train_data, val_data = data_path('/home/abu/Downloads/archive/clear_images', '/home/abu/Downloads/archive/haze'\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c266b263e8b2>\u001b[0m in \u001b[0;36mdata_path\u001b[0;34m(orig_img_path, hazy_img_path)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0morig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_img_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morig_path\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mtrain_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '/home/abu/Downloads/archive/clear_images/0562.png'"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "k_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      \n",
    "regularizer = tf.keras.regularizers.L2(1e-4)\n",
    "b_init = tf.constant_initializer()\n",
    "\n",
    "train_data, val_data = data_path('/home/abu/Downloads/archive/clear_images', '/home/abu/Downloads/archive/haze'\n",
    ")\n",
    "train, val = dataloader(train_data, val_data, batch_size)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4)    # we are using Adam optimizer.\n",
    "net = gman_net()\n",
    "\n",
    "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")    # We are using MSE as loss metrics.\n",
    "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")\n",
    "\n",
    "# Call the training function.\n",
    "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "no such group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-ee2e43ad919e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'he'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"match\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: no such group"
     ]
    }
   ],
   "source": [
    "re.match('h','he')[\"match\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=open('../README.md',\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# ImageDehazing\\n## MIT Final Year project\\n#### Tasks\\n- [x] DCP \\n- [x] Dehazenet model\\n- [x] GCA code\\n- [x] Dataset Loader script\\n- [ ] DeHazeNet Training\\n- [ ] GCA commenting\\n- [ ] BPP\\n- [x] [Make Presentation](https://docs.google.com/presentation/d/183MUhIXfW0YKWMM8UqMhUjYGpJbU1W6hkctT-o8tyxo/edit?usp=sharing)\\n- [ ] cycle Gan\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mDatasets\u001b[0m/  \u001b[01;34mmodels\u001b[0m/    \u001b[01;34mReports\u001b[0m/    \u001b[01;34msampleImg\u001b[0m/  \u001b[01;34mutils\u001b[0m/\n",
      "\u001b[01;34mmetrics\u001b[0m/   README.md  \u001b[01;34mresources\u001b[0m/  \u001b[01;34mtesting\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "os.stat_result(st_mode=33188, st_ino=1207984, st_dev=2055, st_nlink=1, st_uid=1000, st_gid=1000, st_size=329, st_atime=1613740676, st_mtime=1613546772, st_ctime=1613546772)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.stat('../README.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cmpfiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-a90453c6ab58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcmpfiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Datasets'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'../metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cmpfiles' is not defined"
     ]
    }
   ],
   "source": [
    "cmpfiles('../Datasets','../metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
