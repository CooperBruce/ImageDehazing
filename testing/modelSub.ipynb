{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "modelSub.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "scrolled": false,
        "id": "N39U696_KnKD"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NetxtfKRKv7K",
        "outputId": "9bb71057-bbc3-443f-ab36-d5d2824ad634"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FE6nygwKnKd"
      },
      "source": [
        "# Preprocessing and loading of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQvDpNGaB_l"
      },
      "source": [
        "#ls drive/MyDrive/reside/archive/clear_images drive/MyDrive/reside/archive/haze  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "uk0gyj-8KnKe"
      },
      "source": [
        "# function to load the image in the form of tensors.\n",
        "\n",
        "def load_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (412, 548), antialias = True)\n",
        "    img = img / 255.0\n",
        "    return img"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "vvpitygGKnKf"
      },
      "source": [
        "# function to get the path of individual image.\n",
        "\n",
        "def data_path(orig_img_path, hazy_img_path):\n",
        "    \n",
        "    train_img = []\n",
        "    val_img = []\n",
        "    \n",
        "    orig_img = glob.glob(orig_img_path + '/*.jpg')\n",
        "    n = len(orig_img)\n",
        "    random.shuffle(orig_img)\n",
        "    train_keys = orig_img[:int(0.9*n)]        #90% data for train, 10% for test\n",
        "    val_keys = orig_img[int(0.9*n):]\n",
        "    \n",
        "    split_dict = {}\n",
        "    for key in train_keys:\n",
        "        split_dict[key] = 'train'\n",
        "    for key in val_keys:\n",
        "        split_dict[key] = 'val'\n",
        "        \n",
        "    hazy_img = glob.glob(hazy_img_path + '/*.jpg')\n",
        "    for img in hazy_img:\n",
        "        img_name = img.split('/')[-1]\n",
        "        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.jpg'\n",
        "        if (split_dict[orig_path] == 'train'):\n",
        "            train_img.append([img, orig_path])\n",
        "        else:\n",
        "            val_img.append([img, orig_path])\n",
        "            \n",
        "    return train_img, val_img"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "D-194d5sKnKg"
      },
      "source": [
        "# function to load tensor image data in batches.\n",
        "\n",
        "def dataloader(train_data, val_data, batch_size):\n",
        "    \n",
        "    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))\n",
        "    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))\n",
        "    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)\n",
        "    \n",
        "    return train, val"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "2aU_zzDHKnKh"
      },
      "source": [
        "# function to display output.\n",
        "import cv2\n",
        "def display_img(model, hazy_img, orig_img):\n",
        "    \n",
        "    dehazed_img = model(hazy_img, training = True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    \n",
        "    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]\n",
        "    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i])\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()\n",
        "    #print(\"input image quality\",display_list)#niqe(cv2.imread(display_list[1])))\n",
        "    #print(\"input image quality\",niqe(cv2.imread(display_list[2])))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuypKuZZKnKi"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTCX-CqzehI3"
      },
      "source": [
        "class ModelSubClassing(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ModelSubClassing, self).__init__()\n",
        "        # define all layers in init\n",
        "        # Layer of Block 1\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\",padding='same')\n",
        "        \n",
        "        self.conv2 = tf.keras.layers.Conv2D(3, 3, activation=\"relu\",padding='same')\n",
        "        \n",
        "\n",
        "    def call(self, input_tensor, training=False):\n",
        "        # forward pass: block 1 \n",
        "        x = self.conv1(input_tensor)\n",
        "       \n",
        "        x = self.conv2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def model(self):\n",
        "        x = Input(shape = (412, 548, 3))\n",
        "        return Model(inputs=[x], outputs=self.call(x))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htg4Y_MW0Jfo",
        "outputId": "7481bc36-cccc-4303-86df-4fe5b0029027"
      },
      "source": [
        "sub = ModelSubClassing()\n",
        "sub.model().summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 412, 548, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 412, 548, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 412, 548, 3)       1731      \n",
            "=================================================================\n",
            "Total params: 3,523\n",
            "Trainable params: 3,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "id": "HhB7n03AKnKo"
      },
      "source": [
        "# Hyperparameters\n",
        "epochs = 10\n",
        "batch_size = 8\n",
        "k_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      \n",
        "regularizer = tf.keras.regularizers.L2(1e-4)\n",
        "b_init = tf.constant_initializer()\n",
        "\n",
        "train_data, val_data = data_path(orig_img_path = './drive/MyDrive/reside/archive/clear_images', hazy_img_path = './drive/MyDrive/reside/archive/haze')\n",
        "train, val = dataloader(train_data, val_data, batch_size)\n",
        "\n",
        "optimizer = Adam(learning_rate = 1e-4)\n",
        "net = ModelSubClassing()\n",
        "\n",
        "train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"train loss\")\n",
        "val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = \"val loss\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_kg_hide-output": true,
        "id": "L7pz9bV9KnKr"
      },
      "source": [
        "def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        print(\"\\nStart of epoch %d\" % (epoch,), end=' ')\n",
        "        start_time_epoch = time.time()\n",
        "        start_time_step = time.time()\n",
        "        \n",
        "        # training loop\n",
        "        \n",
        "        for step, (train_batch_haze, train_batch_orig) in enumerate(train):\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "                train_logits = net(train_batch_haze, training = True)\n",
        "                #print(train_logits.shape)\n",
        "                loss = mean_squared_error(train_batch_orig, train_logits)\n",
        "\n",
        "            grads = tape.gradient(loss, net.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, net.trainable_weights))\n",
        "\n",
        "            train_loss_tracker.update_state(train_batch_orig, train_logits)\n",
        "            if step == 0:\n",
        "                print('[', end='')\n",
        "            if step % 64 == 0:\n",
        "                print('=', end='')\n",
        "        \n",
        "        print(']', end='')\n",
        "        print('  -  ', end='')\n",
        "        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')\n",
        "        \n",
        "        # validation loop\n",
        "        \n",
        "        for step, (val_batch_haze, val_batch_orig) in enumerate(val):\n",
        "            val_logits = net(val_batch_haze, training = False)\n",
        "            val_loss_tracker.update_state(val_batch_orig, val_logits)\n",
        "            \n",
        "            if step % 32 ==0:\n",
        "                display_img(net, val_batch_haze, val_batch_orig)\n",
        "        \n",
        "        print('  -  ', end='')\n",
        "        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')\n",
        "        print('  -  ', end=' ')\n",
        "        print(\"Time taken: %.2fs\" % (time.time() - start_time_epoch))\n",
        "        \n",
        "        net.save('trained_model')           # save the model(variables, weights, etc)\n",
        "        train_loss_tracker.reset_states()\n",
        "        val_loss_tracker.reset_states()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbnB0QNYKnKs",
        "outputId": "3cc91f0e-4874-48a1-9aef-879b642bd5e5"
      },
      "source": [
        "%%time\n",
        "train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0 [="
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMg7MNzdkWCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fdc74a1-e20a-440a-9799-36088c824204"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 412, 548, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 412, 548, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 412, 548, 3)       1731      \n",
            "=================================================================\n",
            "Total params: 3,523\n",
            "Trainable params: 3,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CinhPC_5OSPB"
      },
      "source": [
        "## Learn"
      ]
    }
  ]
}